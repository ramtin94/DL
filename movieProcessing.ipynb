{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sXqxUCSzLQxe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_SIZE = 1000\n",
        "TEST_SIZE = 200\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "\n",
        "def init_weights(m):\n",
        "    if isinstance(m, torch.nn.Linear) or isinstance(m, torch.nn.Conv2d):\n",
        "        torch.nn.init.xavier_normal_(m.weight)\n",
        "        m.bias.data.fill_(0.01)"
      ],
      "metadata": {
        "id": "uXDY1_zudKPt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample(width, height, movie_length, direction):\n",
        "  frames = list()\n",
        "\n",
        "  last_point_in_frame = [np.random.randint(height), np.random.randint(width)]\n",
        "  for time_index in range(movie_length):\n",
        "    frame = np.ones((height, width))\n",
        "    frame[last_point_in_frame[0], last_point_in_frame[1]] = 0\n",
        "\n",
        "    new_width = last_point_in_frame[1]+direction\n",
        "    new_height = last_point_in_frame[0]+(np.random.randint(0, 3) - 1)\n",
        "\n",
        "    if new_width>=width:\n",
        "      new_width = 0\n",
        "    if new_width<0:\n",
        "      new_width = width - 1\n",
        "\n",
        "    if new_height>=height:\n",
        "      new_height = 0\n",
        "\n",
        "    if new_height<0:\n",
        "      new_height = height - 1\n",
        "\n",
        "    last_point_in_frame[1] = new_width\n",
        "    last_point_in_frame[0] = new_height\n",
        "\n",
        "\n",
        "    frames.append(frame)\n",
        "\n",
        "  frames = np.array(frames)\n",
        "\n",
        "  return frames\n"
      ],
      "metadata": {
        "id": "2aA9dLn2LdQO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw_data = list()\n",
        "train_labels = list()\n",
        "\n",
        "test_raw_data = list()\n",
        "test_labels = list()\n",
        "\n",
        "for _ in range(TRAIN_SIZE):\n",
        "  if np.random.randn()>0.5:\n",
        "    direction = 1\n",
        "    label = 1\n",
        "  else:\n",
        "    direction = -1\n",
        "    label = 0\n",
        "\n",
        "\n",
        "  frames = create_sample(width=15, height=8, movie_length=10, direction=direction)\n",
        "\n",
        "  train_raw_data.append(frames)\n",
        "  train_labels.append(label)\n",
        "\n",
        "train_raw_data = np.array(train_raw_data)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "for _ in range(TEST_SIZE):\n",
        "  if np.random.randn()>0.5:\n",
        "    direction = 1\n",
        "    label = 1\n",
        "  else:\n",
        "    direction = -1\n",
        "    label = 0\n",
        "\n",
        "\n",
        "  frames = create_sample(width=15, height=8, movie_length=10, direction=direction)\n",
        "\n",
        "  test_raw_data.append(frames)\n",
        "  test_labels.append(label)\n",
        "\n",
        "\n",
        "test_raw_data = np.array(test_raw_data)\n",
        "test_labels = np.array(test_labels)\n"
      ],
      "metadata": {
        "id": "5V3gN8JKYtBk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MovieDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, dataset, labels):\n",
        "    super(MovieDataset, self).__init__()\n",
        "\n",
        "    self.dataset = np.expand_dims(dataset, axis=1).astype(np.float32)\n",
        "    self.labels = np.expand_dims(labels, axis=1).astype(np.float32)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    data = self.dataset[index]\n",
        "    label = self.labels[index]\n",
        "\n",
        "    return data, label"
      ],
      "metadata": {
        "id": "pL05B4CDcnye"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MovieClassifier(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MovieClassifier, self).__init__()\n",
        "\n",
        "    self.lstm_hidden_size = 32\n",
        "\n",
        "    self.conv_layers = torch.nn.ModuleList()\n",
        "\n",
        "    input_channel = 1\n",
        "    for channel_index in range(4):\n",
        "      if channel_index<1:\n",
        "        self.conv_layers.append(torch.nn.Conv2d(in_channels=input_channel, out_channels=2*input_channel, kernel_size=(2, 2), stride=(2, 2)))\n",
        "      else:\n",
        "        self.conv_layers.append(torch.nn.Conv2d(in_channels=input_channel, out_channels=2*input_channel, kernel_size=(2, 2), stride=(1, 1)))\n",
        "      input_channel*=2\n",
        "\n",
        "    self.conv_layers.append(torch.nn.Conv2d(in_channels=input_channel, out_channels=4, kernel_size=(1, 1)))\n",
        "    ######################################\n",
        "    self.lstm_layer_1 = torch.nn.LSTM(16, self.lstm_hidden_size, 1, batch_first=True)\n",
        "    ######################################\n",
        "    self.linear_classifier_l1 = torch.nn.Linear(self.lstm_hidden_size, 16)\n",
        "    self.linear_classifier_l2 = torch.nn.Linear(16, 8)\n",
        "    self.linear_classifier_l3 = torch.nn.Linear(8, 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(1, x.size(0), self.lstm_hidden_size)\n",
        "    c0 = torch.zeros(1, x.size(0), self.lstm_hidden_size)\n",
        "\n",
        "    for frame_index in range(x.shape[2]):\n",
        "      frame = x[:, 0, frame_index, :, :].unsqueeze(1)\n",
        "      for layer_index, layer in enumerate(self.conv_layers):\n",
        "        frame = layer(frame)\n",
        "\n",
        "        if layer_index >= 2:\n",
        "          frame = torch.nn.functional.relu(frame)\n",
        "\n",
        "      frame = frame.view(x.size(0), 1, -1)\n",
        "      lstm_out, (h0, c0) = self.lstm_layer_1(frame, (h0, c0))\n",
        "\n",
        "    lstm_out = lstm_out.view(x.size(0), -1)\n",
        "\n",
        "    classifier_output = self.linear_classifier_l1(lstm_out)\n",
        "    classifier_output = self.linear_classifier_l2(classifier_output)\n",
        "    classifier_output = self.linear_classifier_l3(classifier_output)\n",
        "    classifier_output = torch.nn.functional.sigmoid(classifier_output)\n",
        "\n",
        "    return classifier_output\n",
        "\n"
      ],
      "metadata": {
        "id": "io8yUxoPfcHl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_torch_dataset = MovieDataset(dataset=train_raw_data, labels=train_labels)\n",
        "train_dataloader = torch.utils.data.DataLoader(dataset=train_torch_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "test_torch_dataset = MovieDataset(dataset=test_raw_data, labels=test_labels)\n",
        "test_dataloader = torch.utils.data.DataLoader(dataset=test_torch_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "model = MovieClassifier()\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "loss_function = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "hEHd77D4eS6a"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  print(f\"Processing epoch {epoch+1}\")\n",
        "  for data, labels in train_dataloader:\n",
        "    model.zero_grad()\n",
        "\n",
        "    predictions = model(data)\n",
        "\n",
        "    loss = loss_function(predictions, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvtA5YD3e17k",
        "outputId": "68a99285-457e-4e8a-8347-79c3e2307d10"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing epoch 1\n",
            "Loss: 0.8248739242553711\n",
            "Processing epoch 2\n",
            "Loss: 0.5661195516586304\n",
            "Processing epoch 3\n",
            "Loss: 0.5659032464027405\n",
            "Processing epoch 4\n",
            "Loss: 0.5706061124801636\n",
            "Processing epoch 5\n",
            "Loss: 0.5639681816101074\n",
            "Processing epoch 6\n",
            "Loss: 0.570500910282135\n",
            "Processing epoch 7\n",
            "Loss: 0.5644223093986511\n",
            "Processing epoch 8\n",
            "Loss: 0.440577894449234\n",
            "Processing epoch 9\n",
            "Loss: 0.46991297602653503\n",
            "Processing epoch 10\n",
            "Loss: 0.6899201273918152\n",
            "Processing epoch 11\n",
            "Loss: 0.5675331354141235\n",
            "Processing epoch 12\n",
            "Loss: 0.44704771041870117\n",
            "Processing epoch 13\n",
            "Loss: 0.564027726650238\n",
            "Processing epoch 14\n",
            "Loss: 0.6651592254638672\n",
            "Processing epoch 15\n",
            "Loss: 0.8074864745140076\n",
            "Processing epoch 16\n",
            "Loss: 0.5664162635803223\n",
            "Processing epoch 17\n",
            "Loss: 0.5656944513320923\n",
            "Processing epoch 18\n",
            "Loss: 0.6735174655914307\n",
            "Processing epoch 19\n",
            "Loss: 0.45761409401893616\n",
            "Processing epoch 20\n",
            "Loss: 0.45167452096939087\n",
            "Processing epoch 21\n",
            "Loss: 0.6753695607185364\n",
            "Processing epoch 22\n",
            "Loss: 0.791152834892273\n",
            "Processing epoch 23\n",
            "Loss: 0.5678865909576416\n",
            "Processing epoch 24\n",
            "Loss: 0.8159668445587158\n",
            "Processing epoch 25\n",
            "Loss: 0.5719391107559204\n",
            "Processing epoch 26\n",
            "Loss: 0.521388053894043\n",
            "Processing epoch 27\n",
            "Loss: 0.8738957047462463\n",
            "Processing epoch 28\n",
            "Loss: 0.76780104637146\n",
            "Processing epoch 29\n",
            "Loss: 0.6908109188079834\n",
            "Processing epoch 30\n",
            "Loss: 0.5746875405311584\n",
            "Processing epoch 31\n",
            "Loss: 0.7746906876564026\n",
            "Processing epoch 32\n",
            "Loss: 0.5642241835594177\n",
            "Processing epoch 33\n",
            "Loss: 0.4193510115146637\n",
            "Processing epoch 34\n",
            "Loss: 0.5339895486831665\n",
            "Processing epoch 35\n",
            "Loss: 0.5952975749969482\n",
            "Processing epoch 36\n",
            "Loss: 0.7549947500228882\n",
            "Processing epoch 37\n",
            "Loss: 0.8835279941558838\n",
            "Processing epoch 38\n",
            "Loss: 0.5825250744819641\n",
            "Processing epoch 39\n",
            "Loss: 0.3098805248737335\n",
            "Processing epoch 40\n",
            "Loss: 0.28466102480888367\n",
            "Processing epoch 41\n",
            "Loss: 0.1057642251253128\n",
            "Processing epoch 42\n",
            "Loss: 0.0034009243827313185\n",
            "Processing epoch 43\n",
            "Loss: 0.00012825090379919857\n",
            "Processing epoch 44\n",
            "Loss: 0.0011607552878558636\n",
            "Processing epoch 45\n",
            "Loss: 0.07121490687131882\n",
            "Processing epoch 46\n",
            "Loss: 0.0002642546023707837\n",
            "Processing epoch 47\n",
            "Loss: 0.0003982072521466762\n",
            "Processing epoch 48\n",
            "Loss: 0.001319804578088224\n",
            "Processing epoch 49\n",
            "Loss: 7.062809891067445e-05\n",
            "Processing epoch 50\n",
            "Loss: 0.0003263501566834748\n",
            "Processing epoch 51\n",
            "Loss: 8.758933836361393e-05\n",
            "Processing epoch 52\n",
            "Loss: 1.1113437494714162e-06\n",
            "Processing epoch 53\n",
            "Loss: 0.00023543735733255744\n",
            "Processing epoch 54\n",
            "Loss: 8.456681098323315e-05\n",
            "Processing epoch 55\n",
            "Loss: 0.00016391613462474197\n",
            "Processing epoch 56\n",
            "Loss: 0.00016942640650086105\n",
            "Processing epoch 57\n",
            "Loss: 1.873951441666577e-05\n",
            "Processing epoch 58\n",
            "Loss: 8.63413733895868e-05\n",
            "Processing epoch 59\n",
            "Loss: 9.065343328984454e-05\n",
            "Processing epoch 60\n",
            "Loss: 1.8263426682096906e-05\n",
            "Processing epoch 61\n",
            "Loss: 4.0385807551501784e-06\n",
            "Processing epoch 62\n",
            "Loss: 0.00011332824942655861\n",
            "Processing epoch 63\n",
            "Loss: 2.549189593992196e-05\n",
            "Processing epoch 64\n",
            "Loss: 0.00013688938634004444\n",
            "Processing epoch 65\n",
            "Loss: 4.044790694024414e-05\n",
            "Processing epoch 66\n",
            "Loss: 1.8212112991022877e-05\n",
            "Processing epoch 67\n",
            "Loss: 2.682855847524479e-05\n",
            "Processing epoch 68\n",
            "Loss: 1.1665964620988234e-06\n",
            "Processing epoch 69\n",
            "Loss: 6.19663333054632e-05\n",
            "Processing epoch 70\n",
            "Loss: 3.7419299587782007e-06\n",
            "Processing epoch 71\n",
            "Loss: 5.5322623666143045e-05\n",
            "Processing epoch 72\n",
            "Loss: 4.6884895709808916e-05\n",
            "Processing epoch 73\n",
            "Loss: 7.925705176603515e-06\n",
            "Processing epoch 74\n",
            "Loss: 5.7470882893539965e-05\n",
            "Processing epoch 75\n",
            "Loss: 3.429670323384926e-05\n",
            "Processing epoch 76\n",
            "Loss: 1.2518486300905352e-06\n",
            "Processing epoch 77\n",
            "Loss: 2.391840041582327e-07\n",
            "Processing epoch 78\n",
            "Loss: 1.3508275742424303e-06\n",
            "Processing epoch 79\n",
            "Loss: 1.6241776847891742e-06\n",
            "Processing epoch 80\n",
            "Loss: 5.4481766710523516e-05\n",
            "Processing epoch 81\n",
            "Loss: 2.920586666732561e-05\n",
            "Processing epoch 82\n",
            "Loss: 5.045023954153294e-06\n",
            "Processing epoch 83\n",
            "Loss: 1.7409598740414367e-06\n",
            "Processing epoch 84\n",
            "Loss: 1.417733892594697e-05\n",
            "Processing epoch 85\n",
            "Loss: 1.0512878390045444e-07\n",
            "Processing epoch 86\n",
            "Loss: 4.073105446877889e-05\n",
            "Processing epoch 87\n",
            "Loss: 8.30000572022982e-05\n",
            "Processing epoch 88\n",
            "Loss: 0.0002193740801885724\n",
            "Processing epoch 89\n",
            "Loss: 1.265014179807622e-05\n",
            "Processing epoch 90\n",
            "Loss: 1.9507771867210977e-05\n",
            "Processing epoch 91\n",
            "Loss: 1.463370062992908e-05\n",
            "Processing epoch 92\n",
            "Loss: 3.1275219498638762e-06\n",
            "Processing epoch 93\n",
            "Loss: 3.199962293365388e-06\n",
            "Processing epoch 94\n",
            "Loss: 3.679841029224917e-05\n",
            "Processing epoch 95\n",
            "Loss: 6.51100417599082e-05\n",
            "Processing epoch 96\n",
            "Loss: 3.122795078525087e-06\n",
            "Processing epoch 97\n",
            "Loss: 1.363243063678965e-05\n",
            "Processing epoch 98\n",
            "Loss: 8.138585485539807e-07\n",
            "Processing epoch 99\n",
            "Loss: 6.7339915403863415e-06\n",
            "Processing epoch 100\n",
            "Loss: 2.927769673988223e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_list = None\n",
        "true_labels_list = None\n",
        "with torch.no_grad():\n",
        "  for data, labels in test_dataloader:\n",
        "    predictions = torch.round(model(data))\n",
        "\n",
        "    if predictions_list is None:\n",
        "      predictions_list = predictions.detach().numpy()\n",
        "      true_labels_list = labels.detach().numpy()\n",
        "    else:\n",
        "      predictions_list = np.append(predictions_list, predictions.detach().numpy(), axis=0)\n",
        "      true_labels_list = np.append(true_labels_list, labels.detach().numpy(), axis=0)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Accuracy is : {accuracy_score(predictions_list, true_labels_list):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGzcKj6Ae7FU",
        "outputId": "64071c01-e275-4a8f-d184-0cd67f09eb07"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is : 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "81yelqc-g_wb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}