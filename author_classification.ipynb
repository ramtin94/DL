{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6nNwzVQ4EpwA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "#import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6ylO4sj7SOGe"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4Epx7b4LE7XA"
      },
      "outputs": [],
      "source": [
        "train_dataset = pd.read_csv(\"/content/train.csv\")\n",
        "test_dataset = pd.read_csv(\"/content/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "LjbDMQ_-FWR3",
        "outputId": "38cde858-9a06-4a25-84e6-27b59fdce579"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1a34730b-feee-4426-b232-8a921d81b041\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>lung</th>\n",
              "      <th>council</th>\n",
              "      <th>solution</th>\n",
              "      <th>quite</th>\n",
              "      <th>rain</th>\n",
              "      <th>hair</th>\n",
              "      <th>skill</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>add</th>\n",
              "      <th>...</th>\n",
              "      <th>stocking</th>\n",
              "      <th>near</th>\n",
              "      <th>oil</th>\n",
              "      <th>dive</th>\n",
              "      <th>many</th>\n",
              "      <th>run</th>\n",
              "      <th>tender</th>\n",
              "      <th>asleep</th>\n",
              "      <th>eat</th>\n",
              "      <th>sweep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mason Reed</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ava Thompson</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Liam Carter</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mason Reed</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Olivia Bennett</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 381 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a34730b-feee-4426-b232-8a921d81b041')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a34730b-feee-4426-b232-8a921d81b041 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a34730b-feee-4426-b232-8a921d81b041');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4deb7229-e697-42c9-9d52-28fcf7f87f8d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4deb7229-e697-42c9-9d52-28fcf7f87f8d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4deb7229-e697-42c9-9d52-28fcf7f87f8d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           author  lung  council  solution  quite  rain  hair  skill  \\\n",
              "0      Mason Reed     0        0         0      0     0     0      0   \n",
              "1    Ava Thompson     0        0         0      0     0     0      0   \n",
              "2     Liam Carter     0        0         0      0     0     0      0   \n",
              "3      Mason Reed     0        0         0      0     0     0      0   \n",
              "4  Olivia Bennett     0        0         0      0     0     0      0   \n",
              "\n",
              "   difficulty  add  ...  stocking  near  oil  dive  many  run  tender  asleep  \\\n",
              "0           0    0  ...         0     0    0     0     0    0       0       0   \n",
              "1           0    0  ...         0     0    0     0     0    0       0       0   \n",
              "2           0    0  ...         0     0    0     0     0    0       0       0   \n",
              "3           0    0  ...         0     0    0     0     0    0       0       0   \n",
              "4           0    0  ...         0     0    0     0     0    0       0       0   \n",
              "\n",
              "   eat  sweep  \n",
              "0    0      0  \n",
              "1    0      0  \n",
              "2    0      0  \n",
              "3    0      0  \n",
              "4    0      0  \n",
              "\n",
              "[5 rows x 381 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tWFxy0YLZrB",
        "outputId": "710f970a-8fe7-46ac-d316-4f1671387d02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Mason Reed' 'Ava Thompson' 'Liam Carter' ... 'Ava Thompson'\n",
            " 'Ethan Brooks' 'Mason Reed']\n",
            "[3 0 2 ... 0 1 3]\n",
            "['Ava Thompson' 'Ethan Brooks' 'Liam Carter' 'Mason Reed' 'Olivia Bennett']\n"
          ]
        }
      ],
      "source": [
        "data = np.array(train_dataset)\n",
        "Y = data[:, 0]\n",
        "print(Y)\n",
        "le = LabelEncoder()\n",
        "Y_numerical = le.fit_transform(Y)\n",
        "print(Y_numerical)\n",
        "print(le.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "wAiD_PAAFdHe",
        "outputId": "52a9d798-5b3d-4c7f-dd72-6c73989a3e4a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5fa58d57-aaf3-4e54-971c-dd5281574abf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lung</th>\n",
              "      <th>council</th>\n",
              "      <th>solution</th>\n",
              "      <th>quite</th>\n",
              "      <th>rain</th>\n",
              "      <th>hair</th>\n",
              "      <th>skill</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>add</th>\n",
              "      <th>pull</th>\n",
              "      <th>...</th>\n",
              "      <th>stocking</th>\n",
              "      <th>near</th>\n",
              "      <th>oil</th>\n",
              "      <th>dive</th>\n",
              "      <th>many</th>\n",
              "      <th>run</th>\n",
              "      <th>tender</th>\n",
              "      <th>asleep</th>\n",
              "      <th>eat</th>\n",
              "      <th>sweep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 380 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fa58d57-aaf3-4e54-971c-dd5281574abf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5fa58d57-aaf3-4e54-971c-dd5281574abf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5fa58d57-aaf3-4e54-971c-dd5281574abf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-88db482d-d749-4ee5-968b-4b9bbc5901e9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88db482d-d749-4ee5-968b-4b9bbc5901e9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-88db482d-d749-4ee5-968b-4b9bbc5901e9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   lung  council  solution  quite  rain  hair  skill  difficulty  add  pull  \\\n",
              "0     0        0         0      0     0     0      0           0    0     0   \n",
              "1     0        0         0      0     0     0      0           0    0     0   \n",
              "2     0        0         0      0     0     0      0           0    0     0   \n",
              "3     0        0         0      0     0     0      0           0    0     0   \n",
              "4     0        0         0      0     0     0      0           0    0     0   \n",
              "\n",
              "   ...  stocking  near  oil  dive  many  run  tender  asleep  eat  sweep  \n",
              "0  ...         0     0    0     0     0    0       0       0    0      0  \n",
              "1  ...         0     0    0     0     0    0       0       0    0      0  \n",
              "2  ...         0     0    0     0     0    0       0       0    0      0  \n",
              "3  ...         0     0    0     0     0    0       0       0    0      0  \n",
              "4  ...         0     0    0     0     0    0       0       0    0      0  \n",
              "\n",
              "[5 rows x 380 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BQYjpkj-Fe8e"
      },
      "outputs": [],
      "source": [
        "class AuthorClassifier(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AuthorClassifier, self).__init__()\n",
        "\n",
        "    # linear layers (B, 380) -> (B, 5)\n",
        "    self.linear_layers = torch.nn.ModuleList()\n",
        "    self.linear_layers.append(torch.nn.Linear(380, 256))\n",
        "    self.linear_layers.append(torch.nn.Linear(256, 128))\n",
        "    self.linear_layers.append(torch.nn.Linear(128, 16))\n",
        "    self.linear_layers.append(torch.nn.Linear(16, 5))\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.linear_layers:\n",
        "      x = layer(x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Q7PfQZR4KxLz"
      },
      "outputs": [],
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, file_addr):\n",
        "    super(TextDataset, self).__init__()\n",
        "\n",
        "    data = np.array(pd.read_csv(file_addr))\n",
        "    self.X = data[:, 1:].astype(np.float32)\n",
        "    self.Y = data[:, 0]\n",
        "    self.le = LabelEncoder()\n",
        "    self.Y_numerical = self.le.fit_transform(self.Y)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample_X = self.X[index]\n",
        "    sample_Y = self.Y_numerical[index]\n",
        "\n",
        "    return sample_X, sample_Y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD_yC8_yJ8Hl",
        "outputId": "d3a76bf4-7780-45a1-8ec5-ad9d06dff671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 5])\n"
          ]
        }
      ],
      "source": [
        "ath_clf = AuthorClassifier()\n",
        "\n",
        "random_input = torch.randn((16, 380))\n",
        "\n",
        "output = ath_clf(random_input)\n",
        "print(output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "UEjk780TR-Rv"
      },
      "outputs": [],
      "source": [
        "ath_dataset = TextDataset(\"/content/train.csv\")\n",
        "ath_dataloder = torch.utils.data.DataLoader(dataset=ath_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwNXDAtlSjX-",
        "outputId": "666e037c-aebe-4544-8393-c4bdc179a63d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 380])\n",
            "tensor([3, 0, 2, 4, 4, 2, 3, 0, 1, 1, 1, 3, 0, 1, 1, 4, 3, 1, 2, 1, 2, 1, 4, 3,\n",
            "        4, 1, 4, 0, 4, 3, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "for x, label in ath_dataloder:\n",
        "  print(x.shape)\n",
        "  print(label)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgYAomfJTEl2",
        "outputId": "444dcda3-3063-4d27-f47e-1c345b734ff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "predictions = ath_clf(x)\n",
        "_, indices = torch.max(predictions, axis=1)\n",
        "print(indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "sALkWFjWfIL3"
      },
      "outputs": [],
      "source": [
        "ath_dataset = TextDataset(\"/content/train.csv\")\n",
        "ath_dataloder = torch.utils.data.DataLoader(dataset=ath_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "ath_clf = AuthorClassifier()\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(ath_clf.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUE4fbNKezhv",
        "outputId": "676a7dcb-458c-408c-e988-6a04b5dda050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Avg loss: 0.9020199227333069\n",
            "Epoch: 2, Avg loss: 0.5310618034005166\n",
            "Epoch: 3, Avg loss: 0.48014617040753366\n",
            "Epoch: 4, Avg loss: 0.4651152931153774\n",
            "Epoch: 5, Avg loss: 0.4502976153790951\n",
            "Epoch: 6, Avg loss: 0.4402751947939396\n",
            "Epoch: 7, Avg loss: 0.4329556003212929\n",
            "Epoch: 8, Avg loss: 0.4282388833165169\n",
            "Epoch: 9, Avg loss: 0.41835219457745554\n",
            "Epoch: 10, Avg loss: 0.41916834488511084\n",
            "Epoch: 11, Avg loss: 0.41680546224117276\n",
            "Epoch: 12, Avg loss: 0.4183227360248566\n",
            "Epoch: 13, Avg loss: 0.40735626354813576\n",
            "Epoch: 14, Avg loss: 0.4105776792019606\n",
            "Epoch: 15, Avg loss: 0.41098604768514635\n",
            "Epoch: 16, Avg loss: 0.40555464848876\n",
            "Epoch: 17, Avg loss: 0.4034690663218498\n",
            "Epoch: 18, Avg loss: 0.4000151006877422\n",
            "Epoch: 19, Avg loss: 0.4042209202051163\n",
            "Epoch: 20, Avg loss: 0.40381007790565493\n",
            "Epoch: 21, Avg loss: 0.4063101524859667\n",
            "Epoch: 22, Avg loss: 0.40459278419613837\n",
            "Epoch: 23, Avg loss: 0.39617191553115844\n",
            "Epoch: 24, Avg loss: 0.3952113954722881\n",
            "Epoch: 25, Avg loss: 0.3958150053024292\n",
            "Epoch: 26, Avg loss: 0.3963723322749138\n",
            "Epoch: 27, Avg loss: 0.39581503689289094\n",
            "Epoch: 28, Avg loss: 0.39197113886475565\n",
            "Epoch: 29, Avg loss: 0.4052555996924639\n",
            "Epoch: 30, Avg loss: 0.39332587718963624\n",
            "Epoch: 31, Avg loss: 0.3929736506193876\n",
            "Epoch: 32, Avg loss: 0.38861258663237097\n",
            "Epoch: 33, Avg loss: 0.3930298617482185\n",
            "Epoch: 34, Avg loss: 0.3924037852883339\n",
            "Epoch: 35, Avg loss: 0.3894521568715572\n",
            "Epoch: 36, Avg loss: 0.38998768404126166\n",
            "Epoch: 37, Avg loss: 0.3932431675493717\n",
            "Epoch: 38, Avg loss: 0.38993085995316507\n",
            "Epoch: 39, Avg loss: 0.387592081874609\n",
            "Epoch: 40, Avg loss: 0.38565205693244936\n",
            "Epoch: 41, Avg loss: 0.3846952536702156\n",
            "Epoch: 42, Avg loss: 0.3851530130952597\n",
            "Epoch: 43, Avg loss: 0.38904411777853964\n",
            "Epoch: 44, Avg loss: 0.39068497642874717\n",
            "Epoch: 45, Avg loss: 0.3829149200767279\n",
            "Epoch: 46, Avg loss: 0.3845405170321465\n",
            "Epoch: 47, Avg loss: 0.3903660561144352\n",
            "Epoch: 48, Avg loss: 0.38709288880229\n",
            "Epoch: 49, Avg loss: 0.38503040790557863\n",
            "Epoch: 50, Avg loss: 0.3908561206609011\n",
            "Epoch: 51, Avg loss: 0.39153955355286596\n",
            "Epoch: 52, Avg loss: 0.38402083128690717\n",
            "Epoch: 53, Avg loss: 0.381579417437315\n",
            "Epoch: 54, Avg loss: 0.3952243759855628\n",
            "Epoch: 55, Avg loss: 0.38442483462393284\n",
            "Epoch: 56, Avg loss: 0.37920974038541316\n",
            "Epoch: 57, Avg loss: 0.38275257907807825\n",
            "Epoch: 58, Avg loss: 0.38033946849405764\n",
            "Epoch: 59, Avg loss: 0.3865907207131386\n",
            "Epoch: 60, Avg loss: 0.37853239856660365\n",
            "Epoch: 61, Avg loss: 0.3847348375618458\n",
            "Epoch: 62, Avg loss: 0.3809210219979286\n",
            "Epoch: 63, Avg loss: 0.37808435805141927\n",
            "Epoch: 64, Avg loss: 0.38126584738492963\n",
            "Epoch: 65, Avg loss: 0.38392063945531846\n",
            "Epoch: 66, Avg loss: 0.3805911184847355\n",
            "Epoch: 67, Avg loss: 0.38801800087094307\n",
            "Epoch: 68, Avg loss: 0.38206840693950656\n",
            "Epoch: 69, Avg loss: 0.3773366749286652\n",
            "Epoch: 70, Avg loss: 0.3808002868294716\n",
            "Epoch: 71, Avg loss: 0.3816648990660906\n",
            "Epoch: 72, Avg loss: 0.3795988380908966\n",
            "Epoch: 73, Avg loss: 0.3766221322119236\n",
            "Epoch: 74, Avg loss: 0.38104827582836154\n",
            "Epoch: 75, Avg loss: 0.38181713633239267\n",
            "Epoch: 76, Avg loss: 0.381683357283473\n",
            "Epoch: 77, Avg loss: 0.3770658665895462\n",
            "Epoch: 78, Avg loss: 0.3778825099766254\n",
            "Epoch: 79, Avg loss: 0.384573008865118\n",
            "Epoch: 80, Avg loss: 0.3790661029703915\n",
            "Epoch: 81, Avg loss: 0.377987467944622\n",
            "Epoch: 82, Avg loss: 0.38137572780251505\n",
            "Epoch: 83, Avg loss: 0.3754603622108698\n",
            "Epoch: 84, Avg loss: 0.37680766195058824\n",
            "Epoch: 85, Avg loss: 0.3780831834673882\n",
            "Epoch: 86, Avg loss: 0.37277632392942905\n",
            "Epoch: 87, Avg loss: 0.3844727164506912\n",
            "Epoch: 88, Avg loss: 0.37779042407870295\n",
            "Epoch: 89, Avg loss: 0.3762859998643398\n",
            "Epoch: 90, Avg loss: 0.37825234554708004\n",
            "Epoch: 91, Avg loss: 0.38138235911726953\n",
            "Epoch: 92, Avg loss: 0.38497683927416804\n",
            "Epoch: 93, Avg loss: 0.37734281085431576\n",
            "Epoch: 94, Avg loss: 0.37715600669384003\n",
            "Epoch: 95, Avg loss: 0.37443196699023246\n",
            "Epoch: 96, Avg loss: 0.37556463681161406\n",
            "Epoch: 97, Avg loss: 0.3743330518901348\n",
            "Epoch: 98, Avg loss: 0.3772402945160866\n",
            "Epoch: 99, Avg loss: 0.373424616754055\n",
            "Epoch: 100, Avg loss: 0.37406738676130774\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "  list_of_losses = list()\n",
        "  for x, y in ath_dataloder:\n",
        "    ath_clf.zero_grad()\n",
        "\n",
        "    predictions = ath_clf(x)\n",
        "\n",
        "    loss = criterion(predictions, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    list_of_losses.append(loss.item())\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}, Avg loss: {np.mean(list_of_losses)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArLmk2MIgQjg",
        "outputId": "d7a760e3-4c95-43b1-f1bb-dcc433c9ccf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 4, 2, 0, 0, 1, 0, 2, 1, 4, 3, 1, 3, 2, 2, 3, 1, 4, 4, 3, 3, 2, 2, 2,\n",
            "        3, 0, 2, 4])\n",
            "tensor([3, 0, 2, 4, 4, 2, 3, 0, 1, 1, 1, 3, 0, 1, 1, 4, 3, 1, 2, 1, 2, 1, 4, 3,\n",
            "        4, 1, 4, 0, 4, 3, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "predictions = ath_clf(x)\n",
        "_, indices = torch.max(predictions, axis=1)\n",
        "print(indices)\n",
        "print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "2Z7_ERK1k_D9"
      },
      "outputs": [],
      "source": [
        "list_of_labels = list()\n",
        "list_of_predictions = list()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for x, y in ath_dataloder:\n",
        "\n",
        "    _, predictions = torch.max(ath_clf(x), axis=1)\n",
        "\n",
        "    list_of_labels.extend(y.numpy())\n",
        "    list_of_predictions.extend(predictions.numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkwFo0Oulffa",
        "outputId": "ec871c20-ac0d-4a0b-cdb8-ba8b32c6f4ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 0, 3, 2, 0, 3, 4, 3, 2, 4, 0, 1, 1, 3, 2, 0, 4, 4, 0, 3, 2, 1, 4, 1, 2, 0, 2, 4, 0, 4, 4, 0, 4, 3, 1, 0, 4, 3, 3, 1, 0, 0, 1, 3, 1, 1, 0, 3, 3, 2, 3, 1, 0, 4, 4, 4, 0, 2, 3, 3, 4, 0, 2, 1, 2, 3, 4, 1, 2, 0, 4, 0, 3, 4, 1, 0, 2, 2, 0, 4, 3, 0, 4, 2, 1, 2, 4, 3, 0, 1, 1, 4, 1, 0, 2, 4, 0, 2, 0, 3, 0, 4, 3, 4, 1, 1, 3, 0, 1, 2, 0, 3, 1, 1, 1, 3, 2, 3, 0, 2, 4, 2, 1, 2, 1, 1, 3, 0, 0, 0, 4, 3, 0, 2, 3, 3, 1, 2, 3, 2, 3, 1, 0, 1, 2, 2, 4, 0, 4, 1, 2, 0, 3, 2, 4, 3, 2, 4, 0, 1, 1, 3, 1, 3, 4, 0, 3, 2, 2, 2, 1, 2, 0, 2, 3, 3, 3, 1, 2, 1, 3, 0, 1, 3, 3, 1, 2, 1, 1, 3, 1, 1, 1, 1, 0, 4, 2, 3, 1, 1, 4, 4, 1, 4, 4, 4, 3, 1, 0, 3, 0, 1, 2, 1, 0, 3, 0, 0, 1, 2, 3, 4, 3, 3, 3, 4, 3, 4, 3, 1, 3, 1, 1, 4, 1, 3, 0, 1, 0, 4, 1, 4, 3, 4, 4, 3, 3, 0, 0, 4, 1, 1, 4, 2, 3, 2, 0, 3, 2, 4, 0, 1, 1, 1, 0, 2, 4, 0, 3, 2, 3, 3, 0, 4, 0, 0, 3, 0, 4, 4, 4, 2, 0, 1, 0, 0, 2, 4, 2, 4, 2, 3, 1, 2, 1, 3, 0, 4, 2, 1, 4, 0, 4, 2, 2, 2, 2, 2, 1, 4, 3, 3, 0, 2, 4, 3, 0, 2, 1, 1, 0, 0, 1, 3, 1, 4, 1, 4, 1, 3, 3, 1, 0, 3, 3, 1, 3, 2, 1, 1, 2, 2, 0, 2, 2, 1, 4, 2, 2, 4, 3, 4, 1, 3, 0, 0, 4, 4, 1, 4, 0, 0, 0, 3, 0, 4, 0, 0, 4, 0, 4, 2, 3, 2, 2, 3, 1, 1, 3, 2, 4, 4, 1, 0, 0, 0, 1, 1, 0, 4, 0, 0, 4, 0, 1, 3, 2, 3, 2, 2, 2, 2, 4, 4, 3, 2, 3, 4, 4, 2, 0, 2, 1, 0, 1, 1, 3, 2, 0, 4, 1, 4, 2, 3, 0, 3, 0, 1, 4, 3, 1, 2, 4, 2, 1, 3, 0, 0, 1, 2, 3, 3, 3, 0, 3, 4, 1, 4, 1, 1, 4, 0, 2, 1, 0, 4, 2, 1, 0, 4, 0, 0, 0, 2, 1, 3, 1, 1, 3, 2, 4, 1, 0, 3, 3, 0, 0, 0, 3, 1, 3, 0, 2, 1, 3, 3, 2, 1, 3, 3, 2, 4, 4, 4, 1, 2, 3, 4, 4, 2, 0, 2, 0, 3, 2, 4, 2, 2, 4, 1, 0, 0, 3, 2, 4, 1, 4, 4, 0, 4, 1, 2, 3, 3, 1, 1, 1, 3, 4, 0, 2, 2, 4, 4, 1, 4, 4, 2, 2, 3, 4, 4, 3, 1, 3, 3, 4, 0, 3, 0, 3, 1, 1, 0, 4, 3, 2, 0, 3, 0, 4, 4, 1, 4, 0, 4, 2, 4, 4, 3, 1, 0, 3, 3, 4, 3, 4, 0, 4, 2, 3, 0, 3, 1, 3, 3, 4, 2, 3, 4, 0, 4, 4, 1, 2, 4, 0, 3, 2, 2, 3, 4, 3, 0, 3, 2, 1, 3, 0, 1, 2, 2, 3, 3, 0, 4, 0, 2, 3, 2, 3, 2, 3, 2, 4, 1, 2, 0, 4, 2, 4, 4, 3, 0, 3, 2, 1, 4, 3, 4, 0, 3, 1, 4, 4, 1, 0, 4, 4, 2, 2, 0, 2, 0, 1, 3, 2, 2, 1, 3, 2, 3, 2, 2, 2, 3, 3, 1, 2, 3, 2, 3, 3, 4, 4, 0, 2, 2, 2, 4, 4, 3, 4, 0, 1, 3, 2, 2, 0, 1, 0, 1, 3, 1, 4, 4, 4, 2, 0, 0, 3, 2, 3, 2, 0, 1, 4, 0, 0, 0, 2, 2, 3, 4, 1, 4, 4, 0, 4, 0, 1, 1, 2, 1, 3, 1, 3, 2, 0, 0, 3, 4, 0, 1, 3, 2, 3, 2, 2, 1, 2, 3, 4, 4, 4, 2, 2, 1, 4, 4, 3, 2, 4, 4, 4, 3, 4, 0, 2, 1, 1, 3, 0, 0, 0, 0, 1, 0, 3, 3, 0, 3, 0, 3, 3, 1, 0, 0, 0, 1, 3, 3, 4, 0, 2, 0, 2, 1, 1, 0, 4, 0, 1, 1, 1, 3, 4, 2, 1, 1, 4, 4, 3, 2, 0, 4, 0, 2, 2, 3, 1, 2, 2, 4, 2, 2, 2, 1, 2, 0, 2, 2, 3, 3, 0, 0, 0, 4, 4, 0, 4, 2, 0, 2, 3, 0, 0, 3, 1, 3, 4, 4, 1, 2, 1, 3, 1, 1, 0, 2, 2, 4, 1, 1, 0, 4, 3, 3, 1, 4, 0, 0, 3, 1, 4, 2, 1, 2, 2, 1, 0, 2, 0, 3, 4, 4, 0, 4, 2, 3, 4, 0, 4, 2, 4, 0, 2, 2, 3, 0, 0, 4, 0, 1, 2, 2, 3, 1, 4, 3, 3, 1, 4, 1, 4, 0, 0, 3, 3, 4, 1, 0, 3, 2, 3, 0, 0, 1, 0, 0, 2, 2, 0, 3, 4, 1, 4, 4, 1, 0, 1, 1, 0, 3, 1, 1, 4, 2, 1, 4, 3, 4, 2, 0, 0, 1, 2, 3, 4, 3, 3, 3, 3, 0, 2, 0, 1, 3, 2, 1, 2, 4, 1, 1, 2, 0, 4, 1, 1, 2, 1, 3, 2, 1, 2, 0, 4, 0, 3, 1, 4, 4, 3, 3, 1, 0, 1, 4, 2, 3, 2, 1, 4, 3, 1, 4, 4, 4, 4, 4, 1, 3, 0, 0, 3, 2, 1, 3, 4, 3, 0, 1, 3, 4, 4, 0, 3, 2, 3, 4, 4, 2, 4, 1, 2, 4, 3, 2, 2, 1, 2, 3, 4, 3, 2, 3, 3, 0, 4, 4, 1, 0, 2, 3, 4, 0, 0, 4, 1, 4, 2, 3, 3, 3, 3, 2, 0, 0, 2, 3, 0, 2, 4, 1, 4, 0, 0, 2, 1, 0, 0, 0, 1, 4, 4, 4, 4, 4, 4, 0, 2, 4, 1, 4, 2, 0, 2, 2, 1, 2, 4, 4, 3, 3, 3, 2, 4, 0, 3, 3, 2, 1, 1, 2, 3, 0, 0, 1, 4, 4, 3, 2, 2, 3, 1, 1, 3, 4, 2, 2, 4, 4, 3, 4, 1, 2, 0, 1, 1, 3, 2, 3, 3, 2, 4, 1, 0, 2, 4, 0, 0, 2, 0, 1, 3, 1, 1, 0, 1, 2, 1, 3, 3, 4, 4, 2, 2, 3, 3, 4, 1, 1, 3, 4, 1, 4, 1, 3, 2, 3, 2, 0, 4, 3, 3, 3, 2, 4, 2, 2, 1, 1, 1, 4, 1, 2, 4, 1, 2, 0, 4, 1, 0, 1, 3, 3, 0, 3, 3, 0, 3, 4, 3, 2, 4, 1, 2, 0, 3, 0, 0, 2, 0, 3, 3, 3, 4, 3, 4, 3, 1, 2, 2, 0, 1, 0, 4, 2, 3, 4, 1, 3, 1, 4, 0, 1, 3, 0, 4, 0, 2, 4, 3, 1, 4, 3, 4, 3, 3, 4, 3, 1, 0, 1, 3, 4, 3, 2, 2, 3, 2, 1, 4, 4, 0, 3, 3, 1, 2, 4, 0, 2, 1, 4, 2, 1, 3, 4, 2, 2, 1, 1, 3, 0, 0, 1, 4, 3, 0, 2, 4, 1, 0, 4, 4, 0, 3, 3, 4, 2, 3, 4, 4, 2, 1, 2, 0, 3, 0, 2, 0, 4, 4, 3, 4, 2, 0, 1, 1, 1, 3, 2, 0, 2, 1, 1, 2, 4, 4, 2, 4, 4, 1, 0, 3, 1, 4, 3, 0, 3, 4, 4, 2, 3, 0, 1, 3, 0, 2, 3, 1, 4, 3, 1, 3, 3, 3, 4, 3, 0, 1, 1, 0, 3, 3, 0, 4, 4, 4, 4, 0, 4, 0, 0, 3, 4, 3, 3, 4, 2, 2, 2, 1, 3, 0, 3, 1, 2, 3, 4, 0, 4, 3, 4, 3, 0, 3, 2, 0, 0, 4, 1, 0, 2, 4, 0, 1, 3, 4, 1, 0, 4, 3, 0, 0, 3, 1, 1, 4, 0, 4, 4, 0, 1, 0, 3, 0, 2, 0, 1, 4, 3, 3, 3, 4, 3, 1, 3, 0, 2, 4, 4, 2, 4, 3, 1, 4, 1, 2, 4, 2, 1, 2, 4, 0, 1, 1, 4, 1, 3, 3, 3, 1, 4, 4, 3, 0, 4, 2, 4, 2, 4, 3, 0, 3, 2, 3, 2, 1, 2, 2, 2, 2, 1, 3, 2, 4, 0, 3, 1, 3, 0, 2, 0, 2, 0, 4, 4, 2, 3, 2, 3, 1, 4, 2, 4, 4, 4, 4, 1, 0, 3, 4, 1, 2, 1, 3, 2, 0, 2, 3, 2, 3, 0, 1, 0, 2, 0, 0, 2, 4, 3, 3, 2, 4, 0, 3, 4, 1, 1, 1, 1, 2, 3, 4, 2, 3, 4, 1, 1, 0, 3, 0, 3, 0, 2, 4, 2, 3, 2, 4, 0, 3, 1, 0, 0, 2, 3, 1, 0, 4, 3, 4, 0, 1, 1, 2, 0, 1, 0, 1, 2, 3, 1, 2, 3, 1, 2, 1, 4, 4, 2, 2, 2, 2, 0, 4, 1, 0, 2, 2, 0, 0, 3, 4, 0, 0, 4, 1, 4, 2, 2, 2, 3, 3, 2, 1, 0, 4, 1, 3, 3, 3, 3, 4, 1, 1, 3, 4, 2, 1, 2, 3, 1, 2, 3, 4, 2, 0, 0, 3, 4, 2, 1, 3, 2, 4, 2, 4, 4, 1, 3, 2, 4, 1, 0, 4, 3, 2, 3, 3, 4, 0, 3, 1, 2, 3, 0, 4, 4, 2, 0, 1, 0, 1, 3, 2, 0, 3, 4, 0, 2, 2, 4, 3, 4, 3, 3, 1, 2, 4, 3, 4, 0, 4, 0, 2, 1, 3, 1, 4, 0, 2, 0, 3, 3, 3, 3, 0, 0, 4, 2, 2, 2, 1, 4, 3, 4, 2, 0, 0, 1, 3, 2, 0, 0, 1, 4, 0, 0, 2, 0, 4, 1, 1, 0, 3, 2, 2, 4, 2, 4, 4, 2, 1, 1, 2, 1, 2, 3, 1, 4, 3, 1, 4, 1, 0, 1, 3, 0, 1, 2, 0, 3, 3, 0, 1, 1, 3, 4, 1, 4, 4, 2, 4, 0, 0, 0, 2, 3, 3, 0, 0, 0, 1, 3, 2, 4, 0, 2, 4, 2, 4, 2, 2, 3, 0, 3, 3, 2, 2, 3, 0, 4, 3, 3, 3, 1, 0, 4, 2, 3, 3, 0, 1, 0, 0, 2, 1, 0, 1, 0, 0, 0, 3, 1, 2, 2, 0, 2, 4, 4, 2, 1, 4, 3, 3, 3, 4, 0, 0, 4, 0, 4, 1, 1, 1, 0, 1, 2, 4, 2, 4, 2, 3, 3, 2, 1, 2, 0, 2, 0, 1, 0, 2, 2, 1, 3, 3, 2, 3, 0, 1, 2, 3, 2, 2, 1, 0, 0, 3, 2, 1, 1, 2, 4, 0, 1, 1, 2, 2, 4, 0, 2, 1, 0, 2, 3, 3, 3, 2, 4, 1, 4, 2, 1, 3, 0, 4, 2, 1, 2, 1, 0, 3, 3, 1, 0, 2, 3, 0, 1, 2, 0, 1, 2, 2, 3, 3, 1, 3, 0, 1, 2, 4, 0, 1, 1, 0, 0, 4, 0, 2, 2, 1, 3, 4, 3, 1, 4, 0, 1, 4, 1, 4, 3, 3, 3, 2, 3, 3, 4, 0, 0, 0, 1, 4, 3, 2, 0, 2, 0, 2, 0, 0, 4, 0, 0, 1, 0, 0, 2, 3, 4, 2, 3, 4, 0, 0, 0, 2, 4, 4, 1, 0, 1, 2, 1, 2, 2, 4, 1, 3, 0, 3, 0, 3, 2, 4, 1, 3, 1, 0, 1, 3, 4, 1, 1, 3, 0, 1, 0, 1, 4, 3, 1, 0, 0, 4, 3, 2, 2, 4, 0, 0, 3, 4, 0, 4, 2, 4, 3, 4, 1, 4, 1, 1, 3, 3, 4, 2, 4, 3, 0, 4, 2, 0, 4, 3, 1, 3, 0, 3, 1, 4, 1, 1, 1, 1, 3, 4, 0, 1, 1, 1, 0, 4, 2, 2, 4, 3, 0, 2, 2, 3, 4, 3, 0, 0, 1, 1, 4, 1, 1, 0, 4, 3, 3, 4, 1, 3, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 0, 3, 3, 3, 2, 0, 3, 4, 0, 3, 4, 0, 3, 2, 2, 0, 4, 3, 2, 1, 4, 2, 3, 3, 3, 0, 3, 3, 4, 1, 4, 3, 1, 3, 0, 1, 4, 1, 0, 1, 4, 4, 3, 3, 4, 1, 2, 1, 1, 1, 3, 4, 2, 1, 1, 3, 0, 1, 0, 4, 0, 1, 4, 1, 0, 0, 1, 0, 4, 3, 3, 2, 4, 4, 4, 4, 3, 0, 2, 0, 2, 2, 4, 3, 1, 4, 4, 1, 2, 1, 2, 1, 3, 1, 1, 3, 0, 1, 4, 3, 0, 4, 0, 2, 4, 3, 0, 2, 1, 0, 3, 1, 2, 3, 1, 2, 4, 0, 1, 4, 4, 1, 2, 2, 0, 3, 4, 4, 2, 1, 0, 4, 1, 0, 2, 1, 1, 3, 4, 2, 4, 3, 1, 1, 0, 1, 4, 3, 0, 2, 2, 1, 0, 2, 2, 2, 2, 1, 4, 4, 2, 1, 3, 2, 0, 4, 2, 0, 0, 2, 4, 1, 2, 0, 0, 3, 4, 2, 1, 4, 4, 2, 1, 1, 1, 4, 1, 4, 1, 4, 1, 0, 0, 0, 0, 4, 3, 1, 4, 1, 1, 2, 4, 3, 0, 3, 0, 2, 0, 0, 4, 1, 3, 2, 0, 1, 2, 4, 1, 4, 1, 4, 4, 2, 4, 3, 2, 4, 1, 2, 1, 0, 0, 3, 0, 4, 0, 2, 2, 3, 2, 1, 1, 1, 0, 0, 3, 0, 4, 3, 0, 1, 0, 1, 4, 2, 0, 3, 3, 1, 0, 4, 0, 4, 1, 0, 2, 0, 3, 4, 3, 0, 1, 2, 1, 0, 3, 1, 1, 2, 4, 1, 1, 3, 2, 1, 3, 1, 2, 3, 3, 1, 2, 1, 2, 0, 4, 3, 3, 3, 3, 2, 2, 2, 0, 1, 0, 2, 1, 4, 3, 2, 4, 0, 3, 1, 3, 1, 1, 4, 4, 4, 0, 2, 4, 3, 3, 3, 1, 1, 1, 4, 4, 0, 2, 0, 0, 1, 0, 1, 0, 1, 4, 0, 0, 2, 1, 2, 2, 0, 4, 2, 2, 0, 0, 2, 4, 1, 2, 0, 3, 1, 0, 2, 3, 3, 0, 3, 2, 0, 0, 0, 1, 2, 4, 1, 3, 3, 2, 4, 4, 3, 4, 3, 4, 0, 4, 2, 2, 1, 1, 0, 1, 2, 0, 0, 2, 1, 4, 1, 3, 2, 1, 1, 3, 2, 0, 4, 4, 4, 2, 0, 2, 4, 3, 4, 0, 1, 1, 0, 4, 1, 0, 0, 2, 3, 1, 3, 0, 1, 3, 0, 0, 0, 4, 0, 3, 2, 2, 2, 3, 0, 0, 3, 0, 2, 1, 4, 3, 1, 0, 4, 2, 2, 1, 1, 4, 3, 1, 2, 4, 2, 1, 1, 1, 3, 0, 4, 2, 0, 4, 4, 3, 3, 1, 0, 2, 0, 4, 2, 1, 2, 2, 1, 2, 3, 2, 0, 0, 0, 0, 3, 0, 0, 3, 3, 2, 1, 0, 3, 2, 1, 1, 4, 1, 0, 0, 1, 4, 1, 0, 4, 0, 2, 4, 4, 0, 0, 1, 0, 2, 0, 0, 0, 4, 4, 1, 2, 1, 1, 3, 2, 1, 2, 4, 3, 2, 2, 1, 2, 4, 0, 1, 3, 3, 3, 2, 1, 2, 2, 1, 4, 3, 3, 1, 1, 3, 0, 1, 4, 4, 0, 2, 4, 1, 0, 0, 1, 4, 2, 0, 1, 4, 3, 3, 0, 2, 3, 0, 1, 3, 3, 3, 3, 0, 0, 1, 4, 3, 0, 3, 1, 0, 3, 3, 2, 0, 3, 1, 2, 4, 4, 3, 1, 4, 0, 2, 0, 3, 0, 4, 3, 1, 0, 4, 0, 4, 0, 4, 4, 3, 2, 0, 0, 4, 4, 0, 0, 0, 0, 0, 4, 0, 1, 0, 0, 1, 2, 0, 3, 4, 3, 1, 3, 3, 1, 2, 2, 2, 3, 2, 0, 3, 1, 4, 2, 4, 1, 4, 0, 2, 0, 2, 4, 0, 0, 4, 0, 1, 4, 2, 4, 3, 3, 0, 1, 1, 4, 2, 1, 4, 3, 1, 2, 4, 1, 3, 0, 1, 2, 3, 2, 1, 0, 4, 3, 4, 0, 2, 0, 2, 2, 0, 1, 2, 3, 0, 4, 2, 0, 0, 0, 2, 4, 0, 0, 2, 0, 1, 2, 0, 3, 4, 0, 3, 3, 2, 3, 2, 2, 4, 1, 0, 2, 0, 3, 1, 4, 2, 4, 4, 4, 3, 0, 4, 4, 3, 4, 3, 3, 0, 3, 0, 4, 1, 3, 2, 4, 4, 2, 4, 3, 3, 4, 1, 0, 3, 2, 3, 2, 3, 1, 0, 4, 0, 1, 4, 2, 0, 0, 0, 2, 2, 3, 0, 4, 0, 4, 3, 2, 0, 4, 1, 2, 4, 1, 4, 1, 4, 4, 2, 4, 4, 1, 4, 2, 1, 3, 0, 2, 3, 1, 1, 2, 3, 3, 4, 1, 3, 3, 3, 0, 4, 1, 0, 3, 1, 2, 4, 4, 2, 4, 1, 1, 2, 1, 2, 1, 4, 0, 4, 4, 1, 0, 4, 1, 2, 2, 2, 0, 0, 3, 1, 0, 2, 4, 1, 1, 2, 4, 3, 2, 1, 2, 0, 4, 3, 1, 1, 2, 4, 0, 4, 2, 2, 2, 0, 1, 2, 2, 1, 4, 3, 1, 2, 3, 0, 2, 3, 3, 1, 2, 0, 3, 1, 2, 2, 2, 0, 2, 2, 2, 0, 1, 4, 3, 1, 4, 1, 0, 3, 4, 4, 2, 2, 1, 2, 0, 1, 3, 0, 4, 3, 3, 3, 0, 3, 4, 3, 3, 1, 2, 4, 4, 0, 1, 0, 3, 0, 3, 0, 4, 2, 3, 3, 4, 2, 1, 2, 4, 2, 4, 0, 3, 4, 1, 3, 3, 0, 1, 4, 3, 0, 1, 3, 0, 1, 3, 2, 3, 2, 3, 3, 0, 1, 4, 2, 2, 4, 3, 2, 3, 3, 1, 2, 1, 3, 2, 1, 2, 4, 3, 1, 2, 1, 1, 3, 2, 0, 4, 1, 0, 4, 0, 1, 0, 1, 0, 1, 2, 0, 1, 1, 1, 4, 4, 3, 1, 2, 3, 3, 0, 4, 4, 4, 3, 1, 2, 3, 4, 4, 3, 0, 3, 0, 1, 3, 3, 1, 0, 4, 3, 4, 1, 2, 4, 2, 1, 0, 4, 1, 4, 0, 2, 4, 4, 3, 0, 3, 3, 2, 1, 3, 4, 0, 1, 0, 1, 4, 4, 0, 1, 4, 0, 0, 2, 3, 2, 4, 2, 2, 3, 1, 0, 3]\n",
            "[2, 0, 3, 2, 0, 3, 4, 3, 2, 4, 0, 1, 1, 3, 2, 0, 0, 4, 4, 2, 2, 1, 4, 1, 2, 2, 2, 4, 0, 4, 4, 3, 4, 3, 1, 0, 4, 3, 3, 1, 0, 0, 2, 3, 1, 1, 0, 3, 3, 2, 3, 1, 0, 4, 4, 4, 0, 2, 3, 2, 4, 0, 2, 1, 2, 3, 4, 1, 3, 0, 4, 0, 3, 4, 1, 1, 2, 2, 0, 0, 3, 0, 4, 2, 1, 2, 4, 3, 0, 1, 1, 4, 1, 0, 1, 4, 1, 4, 0, 3, 1, 4, 3, 4, 1, 1, 3, 0, 1, 2, 0, 3, 1, 1, 1, 3, 2, 3, 0, 2, 4, 2, 1, 2, 4, 1, 3, 0, 0, 0, 4, 3, 0, 2, 3, 3, 1, 2, 3, 4, 3, 1, 0, 1, 2, 2, 4, 1, 2, 1, 2, 4, 3, 2, 0, 3, 2, 4, 0, 1, 1, 3, 1, 3, 4, 4, 3, 2, 2, 2, 0, 2, 0, 2, 3, 3, 3, 1, 2, 1, 3, 1, 1, 3, 3, 1, 2, 1, 1, 3, 0, 1, 1, 1, 0, 0, 2, 3, 1, 0, 1, 4, 1, 4, 4, 4, 3, 1, 0, 3, 0, 1, 2, 1, 0, 3, 0, 4, 1, 2, 3, 4, 3, 3, 3, 4, 3, 4, 3, 1, 3, 1, 2, 4, 1, 3, 0, 1, 0, 4, 1, 0, 3, 4, 4, 3, 3, 4, 0, 1, 1, 1, 4, 2, 3, 2, 0, 3, 2, 4, 0, 0, 1, 1, 0, 2, 4, 0, 3, 2, 3, 3, 1, 4, 0, 0, 3, 0, 0, 4, 4, 2, 0, 1, 0, 0, 2, 4, 2, 4, 2, 3, 1, 2, 1, 3, 1, 4, 2, 2, 4, 0, 4, 2, 2, 2, 2, 2, 3, 4, 3, 3, 0, 2, 4, 3, 0, 2, 1, 1, 0, 0, 1, 3, 1, 4, 1, 2, 1, 3, 3, 1, 0, 3, 3, 1, 3, 2, 1, 1, 2, 2, 0, 2, 2, 1, 4, 2, 1, 4, 3, 4, 1, 3, 0, 0, 4, 0, 1, 4, 0, 4, 4, 3, 0, 4, 0, 0, 4, 0, 4, 2, 3, 2, 2, 3, 1, 1, 3, 2, 4, 4, 2, 0, 0, 0, 1, 1, 0, 4, 1, 0, 4, 0, 1, 3, 2, 3, 2, 2, 2, 2, 4, 4, 2, 2, 3, 2, 4, 2, 0, 2, 1, 0, 1, 1, 3, 2, 0, 4, 1, 1, 2, 3, 4, 3, 0, 1, 4, 3, 1, 1, 4, 2, 1, 3, 0, 0, 4, 2, 3, 3, 3, 0, 3, 1, 1, 4, 1, 1, 4, 0, 2, 1, 0, 4, 2, 1, 0, 4, 0, 0, 0, 2, 1, 3, 2, 1, 3, 2, 4, 1, 0, 3, 3, 4, 0, 0, 3, 1, 2, 0, 2, 1, 3, 3, 2, 1, 3, 3, 2, 4, 4, 4, 1, 2, 3, 4, 4, 2, 0, 2, 0, 3, 2, 4, 2, 2, 4, 1, 0, 4, 3, 2, 4, 2, 4, 4, 0, 4, 1, 2, 3, 3, 1, 1, 0, 3, 4, 0, 2, 2, 4, 1, 1, 4, 2, 2, 2, 3, 4, 2, 3, 2, 3, 3, 1, 0, 3, 0, 3, 1, 1, 0, 4, 3, 2, 0, 3, 0, 4, 4, 1, 4, 0, 4, 2, 4, 4, 2, 1, 0, 3, 3, 4, 3, 1, 0, 4, 2, 3, 0, 3, 2, 3, 3, 4, 2, 3, 1, 0, 4, 4, 1, 2, 4, 0, 3, 2, 2, 3, 4, 3, 0, 3, 2, 2, 3, 1, 1, 2, 2, 3, 3, 0, 4, 2, 2, 3, 2, 3, 2, 3, 2, 4, 2, 2, 0, 4, 2, 4, 4, 3, 0, 3, 2, 1, 2, 3, 4, 0, 3, 0, 4, 4, 1, 0, 4, 4, 2, 2, 4, 2, 1, 1, 3, 2, 2, 1, 3, 2, 3, 2, 2, 2, 3, 3, 1, 2, 3, 2, 3, 3, 4, 4, 0, 2, 2, 2, 4, 4, 3, 1, 0, 2, 3, 2, 2, 0, 1, 0, 1, 3, 1, 4, 1, 4, 2, 0, 0, 3, 2, 2, 2, 0, 0, 4, 0, 3, 0, 2, 2, 3, 4, 4, 1, 4, 0, 4, 1, 1, 4, 2, 2, 3, 1, 3, 2, 0, 0, 3, 1, 0, 1, 3, 2, 3, 2, 2, 1, 2, 3, 4, 4, 4, 2, 2, 1, 4, 4, 3, 2, 4, 2, 4, 3, 4, 0, 2, 1, 1, 3, 0, 0, 0, 0, 1, 0, 3, 3, 4, 3, 0, 3, 3, 1, 0, 0, 0, 1, 3, 3, 4, 0, 2, 0, 2, 1, 1, 0, 4, 0, 1, 1, 1, 3, 4, 2, 1, 0, 0, 4, 3, 2, 0, 4, 0, 2, 2, 3, 1, 2, 2, 4, 2, 2, 2, 1, 2, 0, 2, 2, 3, 3, 0, 1, 0, 4, 1, 0, 4, 2, 0, 2, 3, 0, 0, 3, 1, 2, 4, 4, 1, 2, 1, 4, 1, 1, 0, 2, 2, 4, 1, 4, 0, 1, 3, 3, 1, 2, 0, 0, 3, 1, 4, 2, 1, 2, 2, 1, 0, 2, 0, 4, 4, 4, 0, 1, 1, 3, 1, 0, 2, 2, 4, 0, 2, 2, 3, 0, 0, 4, 0, 1, 2, 2, 3, 1, 4, 3, 3, 1, 0, 1, 4, 0, 0, 3, 2, 1, 1, 0, 3, 3, 3, 0, 0, 1, 4, 1, 1, 2, 0, 3, 4, 2, 4, 4, 1, 0, 1, 1, 0, 3, 2, 2, 0, 2, 1, 4, 4, 4, 0, 0, 0, 1, 2, 3, 4, 3, 3, 3, 3, 0, 2, 0, 1, 3, 2, 1, 2, 0, 1, 1, 2, 0, 0, 4, 1, 2, 1, 3, 2, 1, 2, 0, 4, 0, 3, 2, 4, 4, 3, 3, 1, 4, 1, 4, 2, 3, 2, 1, 1, 3, 1, 4, 4, 4, 4, 4, 1, 3, 0, 0, 3, 2, 1, 3, 0, 3, 0, 0, 3, 4, 0, 0, 3, 2, 3, 4, 1, 2, 4, 0, 2, 4, 3, 2, 2, 1, 2, 3, 4, 3, 2, 3, 3, 0, 4, 4, 1, 0, 2, 3, 4, 0, 0, 4, 1, 4, 2, 3, 3, 3, 3, 2, 1, 0, 2, 3, 0, 2, 4, 1, 4, 0, 0, 2, 0, 0, 0, 0, 1, 2, 4, 4, 4, 4, 4, 0, 2, 4, 1, 4, 2, 0, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 1, 0, 3, 3, 2, 1, 1, 2, 3, 0, 0, 1, 4, 4, 3, 2, 2, 3, 1, 1, 3, 2, 2, 2, 4, 4, 3, 4, 1, 2, 0, 1, 1, 3, 2, 3, 3, 2, 4, 1, 0, 2, 0, 0, 0, 2, 0, 1, 2, 1, 1, 0, 1, 2, 1, 2, 3, 4, 4, 2, 2, 3, 3, 4, 1, 2, 3, 4, 1, 4, 1, 3, 2, 3, 2, 1, 4, 3, 3, 3, 2, 4, 2, 2, 1, 1, 1, 4, 1, 2, 4, 1, 2, 0, 4, 1, 4, 1, 3, 3, 0, 3, 3, 0, 3, 1, 3, 2, 4, 1, 2, 0, 3, 0, 0, 2, 0, 3, 3, 3, 4, 3, 4, 3, 1, 2, 2, 0, 2, 0, 0, 2, 3, 4, 1, 3, 4, 4, 0, 1, 3, 0, 4, 0, 2, 4, 3, 2, 4, 3, 4, 3, 3, 4, 3, 1, 0, 1, 3, 2, 3, 1, 2, 3, 2, 1, 0, 4, 0, 3, 3, 1, 2, 4, 0, 2, 1, 4, 2, 1, 3, 4, 2, 2, 1, 1, 3, 0, 0, 1, 4, 3, 0, 2, 4, 1, 0, 2, 2, 0, 3, 3, 4, 2, 3, 4, 4, 1, 1, 2, 0, 3, 0, 2, 0, 1, 4, 3, 4, 2, 0, 0, 1, 1, 3, 3, 0, 2, 1, 1, 2, 4, 4, 2, 4, 1, 1, 0, 3, 1, 4, 3, 0, 3, 2, 4, 2, 3, 0, 2, 3, 0, 2, 3, 1, 4, 3, 1, 3, 3, 3, 4, 2, 0, 1, 1, 0, 3, 3, 0, 4, 2, 4, 4, 0, 2, 0, 0, 3, 1, 3, 3, 4, 2, 2, 2, 1, 3, 0, 3, 1, 2, 3, 4, 0, 4, 3, 4, 3, 0, 3, 2, 1, 0, 4, 1, 4, 2, 4, 0, 1, 3, 4, 1, 0, 4, 3, 0, 4, 3, 1, 4, 4, 0, 4, 4, 0, 1, 0, 3, 0, 2, 0, 1, 4, 3, 3, 3, 4, 3, 1, 3, 4, 2, 4, 1, 2, 4, 3, 1, 4, 1, 2, 4, 3, 1, 2, 4, 0, 4, 1, 1, 1, 3, 4, 3, 1, 4, 4, 3, 0, 1, 2, 4, 2, 4, 3, 0, 3, 2, 3, 2, 1, 2, 3, 2, 2, 1, 3, 2, 4, 0, 2, 1, 3, 0, 2, 0, 2, 0, 4, 0, 2, 3, 2, 3, 1, 4, 3, 4, 4, 4, 4, 1, 1, 3, 1, 2, 2, 1, 3, 2, 0, 2, 3, 2, 3, 0, 1, 0, 2, 0, 0, 2, 4, 3, 3, 2, 4, 4, 3, 4, 1, 1, 2, 0, 2, 3, 1, 2, 3, 4, 1, 1, 0, 4, 0, 3, 0, 2, 1, 2, 3, 2, 4, 0, 3, 2, 0, 4, 2, 3, 1, 0, 4, 3, 4, 0, 2, 1, 2, 0, 1, 0, 1, 2, 3, 1, 2, 3, 1, 2, 1, 4, 4, 2, 2, 2, 2, 0, 4, 1, 4, 2, 2, 1, 0, 3, 4, 0, 0, 4, 1, 4, 2, 2, 2, 3, 3, 2, 1, 0, 4, 1, 3, 3, 3, 3, 4, 2, 0, 3, 4, 2, 1, 2, 3, 1, 2, 3, 1, 2, 0, 0, 3, 2, 2, 1, 3, 2, 4, 2, 4, 1, 1, 3, 2, 4, 4, 0, 4, 3, 2, 3, 3, 4, 0, 3, 1, 2, 3, 0, 4, 4, 2, 4, 1, 0, 2, 3, 2, 0, 3, 4, 4, 2, 2, 4, 3, 1, 2, 3, 1, 2, 4, 3, 4, 0, 4, 0, 2, 4, 1, 1, 4, 0, 2, 0, 3, 3, 3, 3, 0, 0, 4, 2, 2, 4, 1, 2, 3, 4, 1, 0, 0, 0, 3, 2, 0, 0, 2, 4, 0, 0, 2, 0, 4, 1, 2, 0, 3, 2, 2, 4, 2, 4, 4, 2, 4, 1, 2, 1, 2, 3, 1, 4, 3, 1, 4, 1, 0, 1, 3, 0, 1, 2, 0, 3, 3, 0, 0, 1, 3, 4, 1, 4, 4, 2, 4, 2, 4, 0, 2, 3, 3, 0, 0, 1, 1, 3, 2, 4, 0, 2, 4, 2, 4, 2, 2, 3, 0, 3, 3, 2, 2, 3, 0, 4, 3, 3, 3, 1, 0, 0, 2, 3, 3, 0, 4, 0, 0, 2, 2, 4, 1, 0, 0, 1, 3, 1, 2, 2, 0, 2, 0, 4, 2, 1, 4, 3, 3, 3, 4, 4, 0, 4, 0, 1, 1, 1, 1, 0, 1, 2, 0, 2, 4, 2, 3, 3, 2, 1, 2, 0, 2, 0, 1, 0, 2, 2, 1, 3, 3, 2, 3, 0, 4, 2, 3, 3, 2, 1, 0, 0, 3, 2, 1, 1, 2, 4, 0, 1, 1, 2, 2, 4, 0, 2, 1, 0, 2, 3, 3, 3, 2, 3, 1, 4, 2, 1, 3, 0, 4, 2, 1, 2, 1, 0, 3, 3, 1, 4, 2, 3, 0, 1, 2, 0, 1, 2, 2, 3, 3, 1, 3, 0, 1, 2, 4, 0, 1, 1, 4, 0, 0, 0, 1, 2, 1, 3, 4, 3, 1, 4, 3, 1, 4, 4, 4, 3, 3, 3, 2, 3, 3, 4, 0, 0, 0, 1, 4, 3, 2, 0, 2, 0, 2, 0, 0, 4, 0, 0, 2, 0, 0, 2, 3, 4, 2, 3, 4, 0, 0, 0, 2, 4, 4, 1, 0, 1, 1, 1, 2, 2, 1, 1, 3, 0, 3, 0, 3, 2, 4, 0, 3, 1, 0, 1, 3, 4, 0, 1, 3, 0, 1, 0, 4, 4, 3, 1, 0, 0, 1, 3, 2, 2, 4, 0, 0, 3, 4, 0, 4, 2, 2, 3, 4, 1, 4, 1, 4, 3, 3, 4, 2, 4, 3, 0, 4, 2, 0, 4, 3, 1, 3, 0, 3, 1, 4, 1, 1, 1, 1, 3, 4, 0, 1, 1, 1, 0, 1, 2, 2, 0, 3, 0, 2, 2, 3, 4, 3, 0, 0, 1, 0, 4, 1, 1, 0, 4, 3, 3, 4, 1, 3, 2, 0, 0, 1, 0, 2, 2, 2, 0, 2, 0, 3, 3, 3, 3, 0, 3, 4, 4, 3, 4, 1, 3, 2, 2, 0, 4, 3, 2, 1, 4, 2, 3, 3, 3, 0, 2, 3, 4, 1, 4, 3, 1, 3, 0, 4, 4, 1, 0, 0, 4, 4, 3, 3, 4, 1, 2, 1, 1, 1, 3, 4, 2, 1, 1, 3, 1, 4, 0, 1, 0, 1, 4, 2, 0, 0, 1, 0, 4, 3, 3, 2, 4, 4, 4, 4, 3, 0, 2, 0, 2, 2, 4, 3, 1, 4, 4, 1, 2, 1, 2, 1, 3, 1, 1, 3, 0, 1, 4, 3, 0, 4, 0, 2, 4, 3, 0, 3, 4, 0, 3, 1, 1, 3, 1, 3, 4, 0, 1, 4, 4, 1, 2, 2, 0, 3, 4, 4, 2, 1, 0, 4, 1, 0, 2, 1, 1, 3, 1, 2, 4, 3, 1, 1, 0, 1, 4, 3, 0, 2, 2, 1, 0, 2, 2, 3, 2, 1, 4, 2, 2, 1, 3, 2, 0, 2, 3, 0, 0, 2, 2, 1, 2, 0, 0, 3, 4, 2, 1, 4, 4, 2, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 0, 0, 0, 4, 3, 1, 4, 1, 1, 2, 4, 3, 1, 3, 0, 2, 0, 0, 4, 1, 3, 2, 0, 1, 2, 4, 2, 4, 1, 4, 4, 2, 4, 3, 2, 4, 1, 2, 1, 1, 0, 3, 1, 4, 0, 2, 2, 3, 2, 1, 1, 1, 4, 0, 4, 3, 1, 3, 0, 1, 0, 1, 4, 2, 0, 3, 3, 1, 0, 4, 0, 4, 1, 0, 2, 0, 3, 4, 3, 0, 1, 2, 1, 0, 3, 4, 1, 2, 1, 2, 3, 3, 2, 0, 3, 1, 2, 3, 3, 1, 2, 1, 4, 0, 4, 3, 3, 3, 3, 2, 2, 2, 0, 1, 0, 2, 2, 4, 3, 2, 4, 0, 3, 1, 3, 1, 1, 4, 1, 4, 0, 2, 4, 3, 3, 3, 1, 1, 1, 4, 0, 0, 2, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 2, 1, 2, 2, 0, 4, 2, 2, 1, 0, 2, 4, 1, 2, 0, 3, 1, 0, 2, 3, 3, 0, 3, 2, 0, 0, 0, 1, 2, 4, 1, 3, 3, 2, 4, 4, 3, 4, 3, 4, 0, 1, 2, 2, 4, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 3, 2, 2, 1, 3, 2, 1, 4, 1, 4, 2, 1, 2, 4, 3, 4, 0, 1, 1, 0, 1, 4, 4, 0, 2, 3, 1, 3, 0, 1, 3, 0, 4, 1, 4, 0, 3, 2, 2, 2, 3, 0, 0, 3, 0, 2, 1, 4, 3, 2, 0, 4, 2, 1, 2, 0, 4, 3, 1, 2, 4, 2, 1, 4, 0, 3, 0, 4, 2, 0, 4, 4, 3, 3, 1, 2, 2, 0, 4, 2, 4, 2, 2, 1, 2, 3, 3, 0, 4, 0, 0, 3, 0, 4, 3, 3, 2, 3, 0, 3, 2, 1, 1, 4, 1, 0, 0, 1, 4, 3, 0, 4, 0, 2, 4, 4, 0, 0, 1, 1, 2, 0, 0, 0, 0, 4, 1, 2, 2, 1, 3, 2, 1, 2, 0, 3, 2, 2, 2, 2, 4, 1, 1, 3, 3, 3, 3, 1, 2, 2, 1, 4, 3, 3, 1, 1, 3, 0, 1, 4, 1, 0, 2, 4, 2, 0, 0, 1, 4, 2, 0, 1, 0, 3, 3, 0, 2, 3, 0, 1, 3, 3, 3, 3, 0, 0, 1, 4, 3, 0, 3, 1, 4, 3, 3, 2, 0, 3, 1, 2, 4, 4, 3, 2, 4, 4, 2, 0, 3, 0, 4, 2, 2, 0, 4, 0, 4, 1, 2, 4, 3, 2, 0, 0, 4, 4, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 2, 1, 3, 4, 3, 1, 3, 3, 1, 2, 2, 2, 3, 2, 0, 3, 4, 0, 2, 4, 2, 4, 0, 2, 1, 2, 0, 0, 0, 4, 4, 1, 4, 2, 4, 3, 3, 0, 1, 1, 4, 2, 1, 4, 3, 1, 2, 4, 1, 3, 0, 1, 2, 3, 2, 2, 0, 4, 3, 4, 0, 2, 0, 2, 2, 0, 4, 2, 3, 0, 2, 2, 0, 0, 0, 2, 4, 0, 0, 2, 0, 1, 2, 0, 3, 0, 0, 3, 3, 2, 3, 2, 2, 4, 1, 0, 2, 0, 3, 1, 4, 2, 4, 4, 1, 3, 4, 4, 4, 3, 4, 3, 3, 0, 3, 4, 4, 2, 3, 1, 1, 4, 2, 4, 3, 3, 4, 1, 0, 3, 2, 3, 2, 3, 1, 0, 4, 0, 1, 4, 2, 0, 2, 0, 2, 2, 3, 0, 4, 2, 4, 3, 2, 0, 4, 1, 3, 1, 1, 4, 1, 4, 4, 2, 4, 0, 1, 4, 2, 1, 3, 0, 2, 3, 1, 2, 2, 3, 3, 4, 1, 3, 3, 3, 0, 1, 1, 0, 3, 1, 2, 4, 2, 2, 4, 3, 2, 2, 1, 2, 1, 2, 0, 4, 4, 1, 1, 0, 2, 2, 2, 2, 0, 0, 3, 2, 0, 2, 4, 2, 1, 2, 4, 3, 2, 1, 2, 0, 4, 3, 1, 1, 2, 4, 1, 4, 2, 1, 2, 0, 1, 2, 2, 1, 4, 3, 1, 2, 3, 0, 2, 3, 3, 1, 2, 0, 3, 1, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 3, 2, 2, 1, 0, 3, 4, 1, 2, 2, 1, 2, 0, 1, 3, 0, 4, 3, 3, 3, 0, 3, 0, 3, 3, 1, 2, 1, 4, 0, 1, 0, 3, 0, 2, 0, 4, 2, 3, 3, 4, 2, 1, 2, 4, 2, 1, 0, 3, 4, 4, 3, 3, 4, 1, 4, 3, 0, 1, 3, 0, 1, 3, 2, 3, 2, 3, 3, 4, 4, 4, 2, 2, 4, 3, 2, 3, 3, 1, 2, 1, 3, 2, 1, 2, 1, 3, 1, 2, 1, 1, 3, 2, 4, 4, 1, 0, 4, 0, 1, 4, 1, 0, 1, 2, 0, 1, 4, 1, 4, 2, 3, 1, 2, 3, 3, 0, 4, 4, 4, 3, 4, 2, 3, 4, 4, 3, 0, 3, 0, 1, 3, 3, 1, 1, 4, 3, 4, 1, 2, 4, 2, 1, 0, 4, 1, 1, 1, 1, 4, 4, 3, 0, 3, 2, 2, 1, 3, 4, 0, 1, 1, 1, 4, 4, 0, 1, 4, 0, 0, 2, 3, 2, 0, 2, 2, 3, 1, 0, 3]\n"
          ]
        }
      ],
      "source": [
        "print(list_of_labels)\n",
        "print(list_of_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQOvgZkwljkC",
        "outputId": "c8a4e4be-3184-49a0-a323-6341e02604b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8764080100125157\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_score(list_of_labels, list_of_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPiC3uI5mO_c"
      },
      "source": [
        "# Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Kcp3fGgtmejS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "O2Qo6qRgl-Ny"
      },
      "outputs": [],
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, data):\n",
        "    super(TextDataset, self).__init__()\n",
        "\n",
        "    data = np.array(data)\n",
        "    self.X = data[:, 1:].astype(np.float32)\n",
        "    self.Y = data[:, 0]\n",
        "    self.le = LabelEncoder()\n",
        "    self.Y_numerical = self.le.fit_transform(self.Y)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample_X = self.X[index]\n",
        "    sample_Y = self.Y_numerical[index]\n",
        "\n",
        "    return sample_X, sample_Y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "66-Ru9dymaFD"
      },
      "outputs": [],
      "source": [
        "train_dataset = pd.read_csv(\"/content/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "frB_mkOtmitC"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = train_test_split(train_dataset, test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUkEn_kHmqfA",
        "outputId": "aa047f24-ec90-4eb1-bcba-5594b4e461fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2556\n"
          ]
        }
      ],
      "source": [
        "train_data.head()\n",
        "print(len(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFklKDJImsoA",
        "outputId": "ec769ade-afa3-4a31-fe27-bed98143d941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "640\n"
          ]
        }
      ],
      "source": [
        "test_data.head()\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "FXWWbVQYm7iF"
      },
      "outputs": [],
      "source": [
        "ath_train_dataset = TextDataset(train_data)\n",
        "ath_train_dataloder = torch.utils.data.DataLoader(dataset=ath_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "ath_test_dataset = TextDataset(test_data)\n",
        "ath_test_dataloder = torch.utils.data.DataLoader(dataset=ath_test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "ath_clf = AuthorClassifier()\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(ath_clf.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ivx4UzTnYZO",
        "outputId": "c3c1b31c-530a-4883-c5ee-a392913eb1a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Avg loss: 0.31940041286870835\n",
            "Epoch: 2, Avg loss: 0.31784738288260994\n",
            "Epoch: 3, Avg loss: 0.3182787746191025\n",
            "Epoch: 4, Avg loss: 0.31808258816599844\n",
            "Epoch: 5, Avg loss: 0.3168470785021782\n",
            "Epoch: 6, Avg loss: 0.3186693095602095\n",
            "Epoch: 7, Avg loss: 0.3166503610089421\n",
            "Epoch: 8, Avg loss: 0.31723378589376805\n",
            "Epoch: 9, Avg loss: 0.31560068065300584\n",
            "Epoch: 10, Avg loss: 0.3163878694176674\n",
            "Epoch: 11, Avg loss: 0.31637666281312704\n",
            "Epoch: 12, Avg loss: 0.3151310818269849\n",
            "Epoch: 13, Avg loss: 0.31655296916142106\n",
            "Epoch: 14, Avg loss: 0.31540687223896385\n",
            "Epoch: 15, Avg loss: 0.31515681445598603\n",
            "Epoch: 16, Avg loss: 0.31426525861024857\n",
            "Epoch: 17, Avg loss: 0.3144592451862991\n",
            "Epoch: 18, Avg loss: 0.31418724423274397\n",
            "Epoch: 19, Avg loss: 0.3145308017730713\n",
            "Epoch: 20, Avg loss: 0.31335698133334516\n",
            "Epoch: 21, Avg loss: 0.31416023736819626\n",
            "Epoch: 22, Avg loss: 0.3134372979402542\n",
            "Epoch: 23, Avg loss: 0.31262184157967565\n",
            "Epoch: 24, Avg loss: 0.31269003357738256\n",
            "Epoch: 25, Avg loss: 0.3128433283418417\n",
            "Epoch: 26, Avg loss: 0.31237541483715175\n",
            "Epoch: 27, Avg loss: 0.3122283289209008\n",
            "Epoch: 28, Avg loss: 0.3122963223606348\n",
            "Epoch: 29, Avg loss: 0.31304858746007086\n",
            "Epoch: 30, Avg loss: 0.31145087294280527\n",
            "Epoch: 31, Avg loss: 0.3105192749761045\n",
            "Epoch: 32, Avg loss: 0.3119111303240061\n",
            "Epoch: 33, Avg loss: 0.3111941677518189\n",
            "Epoch: 34, Avg loss: 0.3107312730513513\n",
            "Epoch: 35, Avg loss: 0.31016019228845837\n",
            "Epoch: 36, Avg loss: 0.3106903992127627\n",
            "Epoch: 37, Avg loss: 0.31037550619803367\n",
            "Epoch: 38, Avg loss: 0.30986509639769794\n",
            "Epoch: 39, Avg loss: 0.3091939315199852\n",
            "Epoch: 40, Avg loss: 0.31009114235639573\n",
            "Epoch: 41, Avg loss: 0.3105724938213825\n",
            "Epoch: 42, Avg loss: 0.3096226551569998\n",
            "Epoch: 43, Avg loss: 0.30899179056286813\n",
            "Epoch: 44, Avg loss: 0.30927779953926804\n",
            "Epoch: 45, Avg loss: 0.3103660772554576\n",
            "Epoch: 46, Avg loss: 0.3078161275945604\n",
            "Epoch: 47, Avg loss: 0.30874735834077\n",
            "Epoch: 48, Avg loss: 0.3078692791052163\n",
            "Epoch: 49, Avg loss: 0.3086159174330533\n",
            "Epoch: 50, Avg loss: 0.30857564490288497\n",
            "Epoch: 51, Avg loss: 0.3101879874244332\n",
            "Epoch: 52, Avg loss: 0.30755435656756164\n",
            "Epoch: 53, Avg loss: 0.3076613458804786\n",
            "Epoch: 54, Avg loss: 0.3072407653555274\n",
            "Epoch: 55, Avg loss: 0.30795428678393366\n",
            "Epoch: 56, Avg loss: 0.30782727878540755\n",
            "Epoch: 57, Avg loss: 0.30755746392533184\n",
            "Epoch: 58, Avg loss: 0.30693099796772005\n",
            "Epoch: 59, Avg loss: 0.3072247974108905\n",
            "Epoch: 60, Avg loss: 0.3082588707096875\n",
            "Epoch: 61, Avg loss: 0.3072569023817778\n",
            "Epoch: 62, Avg loss: 0.30630120169371367\n",
            "Epoch: 63, Avg loss: 0.3062859853729606\n",
            "Epoch: 64, Avg loss: 0.3051480044610798\n",
            "Epoch: 65, Avg loss: 0.30823583584278824\n",
            "Epoch: 66, Avg loss: 0.30801830659620466\n",
            "Epoch: 67, Avg loss: 0.3063224397599697\n",
            "Epoch: 68, Avg loss: 0.3063584705814719\n",
            "Epoch: 69, Avg loss: 0.30600321730598806\n",
            "Epoch: 70, Avg loss: 0.30632595815695823\n",
            "Epoch: 71, Avg loss: 0.30668368586339056\n",
            "Epoch: 72, Avg loss: 0.3064668921753764\n",
            "Epoch: 73, Avg loss: 0.3063295197673142\n",
            "Epoch: 74, Avg loss: 0.3060632009059191\n",
            "Epoch: 75, Avg loss: 0.30567719442769886\n",
            "Epoch: 76, Avg loss: 0.3084874223917723\n",
            "Epoch: 77, Avg loss: 0.3062223704531789\n",
            "Epoch: 78, Avg loss: 0.3049760074354708\n",
            "Epoch: 79, Avg loss: 0.30478567304089665\n",
            "Epoch: 80, Avg loss: 0.30538476360961797\n",
            "Epoch: 81, Avg loss: 0.30550413075834515\n",
            "Epoch: 82, Avg loss: 0.3050381910987198\n",
            "Epoch: 83, Avg loss: 0.30444427086040377\n",
            "Epoch: 84, Avg loss: 0.30444952864199876\n",
            "Epoch: 85, Avg loss: 0.304594861343503\n",
            "Epoch: 86, Avg loss: 0.3057042010128498\n",
            "Epoch: 87, Avg loss: 0.3041871740482748\n",
            "Epoch: 88, Avg loss: 0.30501440903171895\n",
            "Epoch: 89, Avg loss: 0.3042929111048579\n",
            "Epoch: 90, Avg loss: 0.30403974214568735\n",
            "Epoch: 91, Avg loss: 0.30533592849969865\n",
            "Epoch: 92, Avg loss: 0.30506980484351515\n",
            "Epoch: 93, Avg loss: 0.30410146079957484\n",
            "Epoch: 94, Avg loss: 0.30502923964522777\n",
            "Epoch: 95, Avg loss: 0.30389033518731595\n",
            "Epoch: 96, Avg loss: 0.3042389165610075\n",
            "Epoch: 97, Avg loss: 0.30365237407386303\n",
            "Epoch: 98, Avg loss: 0.3038062371313572\n",
            "Epoch: 99, Avg loss: 0.30475913528352977\n",
            "Epoch: 100, Avg loss: 0.30363944340497256\n",
            "Epoch: 101, Avg loss: 0.30369809838011863\n",
            "Epoch: 102, Avg loss: 0.3048474932089448\n",
            "Epoch: 103, Avg loss: 0.304063013009727\n",
            "Epoch: 104, Avg loss: 0.30413428638130424\n",
            "Epoch: 105, Avg loss: 0.3030101116746664\n",
            "Epoch: 106, Avg loss: 0.30318422252312305\n",
            "Epoch: 107, Avg loss: 0.30458438089117407\n",
            "Epoch: 108, Avg loss: 0.30457361303269864\n",
            "Epoch: 109, Avg loss: 0.30507568549364805\n",
            "Epoch: 110, Avg loss: 0.3025084467604756\n",
            "Epoch: 111, Avg loss: 0.3035971033386886\n",
            "Epoch: 112, Avg loss: 0.3029205292463303\n",
            "Epoch: 113, Avg loss: 0.30357477022334933\n",
            "Epoch: 114, Avg loss: 0.305126978456974\n",
            "Epoch: 115, Avg loss: 0.30271508814767\n",
            "Epoch: 116, Avg loss: 0.30241345139220355\n",
            "Epoch: 117, Avg loss: 0.30397296939045193\n",
            "Epoch: 118, Avg loss: 0.3034829933429137\n",
            "Epoch: 119, Avg loss: 0.30191597966477274\n",
            "Epoch: 120, Avg loss: 0.3025283136405051\n",
            "Epoch: 121, Avg loss: 0.3020736237987876\n",
            "Epoch: 122, Avg loss: 0.3032090222463012\n",
            "Epoch: 123, Avg loss: 0.30252566253766416\n",
            "Epoch: 124, Avg loss: 0.302309000864625\n",
            "Epoch: 125, Avg loss: 0.3021185559220612\n",
            "Epoch: 126, Avg loss: 0.3051656869240105\n",
            "Epoch: 127, Avg loss: 0.3032370852306485\n",
            "Epoch: 128, Avg loss: 0.3035184467211366\n",
            "Epoch: 129, Avg loss: 0.3032274183817208\n",
            "Epoch: 130, Avg loss: 0.3034275369718671\n",
            "Epoch: 131, Avg loss: 0.30235216561704875\n",
            "Epoch: 132, Avg loss: 0.30308641884475945\n",
            "Epoch: 133, Avg loss: 0.3021007624454796\n",
            "Epoch: 134, Avg loss: 0.30288916677236555\n",
            "Epoch: 135, Avg loss: 0.301399286929518\n",
            "Epoch: 136, Avg loss: 0.3021466167643666\n",
            "Epoch: 137, Avg loss: 0.30335388807579877\n",
            "Epoch: 138, Avg loss: 0.3025903388857841\n",
            "Epoch: 139, Avg loss: 0.30103854052722456\n",
            "Epoch: 140, Avg loss: 0.30263038938865067\n",
            "Epoch: 141, Avg loss: 0.30212732311338186\n",
            "Epoch: 142, Avg loss: 0.30329188602045176\n",
            "Epoch: 143, Avg loss: 0.30176572324708106\n",
            "Epoch: 144, Avg loss: 0.3036272018682212\n",
            "Epoch: 145, Avg loss: 0.3017764027230442\n",
            "Epoch: 146, Avg loss: 0.3016432558186352\n",
            "Epoch: 147, Avg loss: 0.3010583113878965\n",
            "Epoch: 148, Avg loss: 0.3041551074013114\n",
            "Epoch: 149, Avg loss: 0.30173409469425677\n",
            "Epoch: 150, Avg loss: 0.3018723572604358\n",
            "Epoch: 151, Avg loss: 0.3022537400946021\n",
            "Epoch: 152, Avg loss: 0.3014153007883579\n",
            "Epoch: 153, Avg loss: 0.3029354441910982\n",
            "Epoch: 154, Avg loss: 0.3015756268054247\n",
            "Epoch: 155, Avg loss: 0.30189451510086657\n",
            "Epoch: 156, Avg loss: 0.3014360698405653\n",
            "Epoch: 157, Avg loss: 0.30069936835207045\n",
            "Epoch: 158, Avg loss: 0.30209304988384245\n",
            "Epoch: 159, Avg loss: 0.30125050535425546\n",
            "Epoch: 160, Avg loss: 0.3031314707361162\n",
            "Epoch: 161, Avg loss: 0.3010135332122445\n",
            "Epoch: 162, Avg loss: 0.3012151944451034\n",
            "Epoch: 163, Avg loss: 0.30137423211708664\n",
            "Epoch: 164, Avg loss: 0.301350019313395\n",
            "Epoch: 165, Avg loss: 0.3008754139766097\n",
            "Epoch: 166, Avg loss: 0.3018429983407259\n",
            "Epoch: 167, Avg loss: 0.30159767232835294\n",
            "Epoch: 168, Avg loss: 0.30218613538891076\n",
            "Epoch: 169, Avg loss: 0.30223997700959443\n",
            "Epoch: 170, Avg loss: 0.30170245505869386\n",
            "Epoch: 171, Avg loss: 0.30031432611867787\n",
            "Epoch: 172, Avg loss: 0.30271120723336936\n",
            "Epoch: 173, Avg loss: 0.30167507296428087\n",
            "Epoch: 174, Avg loss: 0.3015385250560939\n",
            "Epoch: 175, Avg loss: 0.30205336324870585\n",
            "Epoch: 176, Avg loss: 0.30155876809731125\n",
            "Epoch: 177, Avg loss: 0.3022247000597417\n",
            "Epoch: 178, Avg loss: 0.3010977227240801\n",
            "Epoch: 179, Avg loss: 0.30076566291972995\n",
            "Epoch: 180, Avg loss: 0.30070473486557603\n",
            "Epoch: 181, Avg loss: 0.3015241254121065\n",
            "Epoch: 182, Avg loss: 0.3005184869281948\n",
            "Epoch: 183, Avg loss: 0.30122002884745597\n",
            "Epoch: 184, Avg loss: 0.3019644219428301\n",
            "Epoch: 185, Avg loss: 0.3012843234464526\n",
            "Epoch: 186, Avg loss: 0.30216987179592253\n",
            "Epoch: 187, Avg loss: 0.3008073292672634\n",
            "Epoch: 188, Avg loss: 0.3011520800180733\n",
            "Epoch: 189, Avg loss: 0.3008488200604916\n",
            "Epoch: 190, Avg loss: 0.30170210273936393\n",
            "Epoch: 191, Avg loss: 0.3011828761547804\n",
            "Epoch: 192, Avg loss: 0.3010815208777785\n",
            "Epoch: 193, Avg loss: 0.30182611392810943\n",
            "Epoch: 194, Avg loss: 0.30097785172984004\n",
            "Epoch: 195, Avg loss: 0.3008245935663581\n",
            "Epoch: 196, Avg loss: 0.3033276517875493\n",
            "Epoch: 197, Avg loss: 0.30107029508799316\n",
            "Epoch: 198, Avg loss: 0.30079310992732644\n",
            "Epoch: 199, Avg loss: 0.3014884571544826\n",
            "Epoch: 200, Avg loss: 0.3010071556083858\n",
            "Epoch: 201, Avg loss: 0.30079146903008225\n",
            "Epoch: 202, Avg loss: 0.30168252075091007\n",
            "Epoch: 203, Avg loss: 0.3009013716131449\n",
            "Epoch: 204, Avg loss: 0.29956476790830494\n",
            "Epoch: 205, Avg loss: 0.30105694495141505\n",
            "Epoch: 206, Avg loss: 0.2989620348438621\n",
            "Epoch: 207, Avg loss: 0.30055456133559344\n",
            "Epoch: 208, Avg loss: 0.30030259899795053\n",
            "Epoch: 209, Avg loss: 0.30148319955915215\n",
            "Epoch: 210, Avg loss: 0.30071185873821377\n",
            "Epoch: 211, Avg loss: 0.3028097875416279\n",
            "Epoch: 212, Avg loss: 0.30157642988488076\n",
            "Epoch: 213, Avg loss: 0.30135174188762903\n",
            "Epoch: 214, Avg loss: 0.2989030467346311\n",
            "Epoch: 215, Avg loss: 0.3011164731346071\n",
            "Epoch: 216, Avg loss: 0.301759650465101\n",
            "Epoch: 217, Avg loss: 0.3012828206643462\n",
            "Epoch: 218, Avg loss: 0.30076452242210505\n",
            "Epoch: 219, Avg loss: 0.3002186297439039\n",
            "Epoch: 220, Avg loss: 0.2999128042720258\n",
            "Epoch: 221, Avg loss: 0.3001236390322447\n",
            "Epoch: 222, Avg loss: 0.3012711685150862\n",
            "Epoch: 223, Avg loss: 0.30088405776768923\n",
            "Epoch: 224, Avg loss: 0.29981345422565936\n",
            "Epoch: 225, Avg loss: 0.30052023781463505\n",
            "Epoch: 226, Avg loss: 0.3009242543950677\n",
            "Epoch: 227, Avg loss: 0.2998605104163289\n",
            "Epoch: 228, Avg loss: 0.3005133142694831\n",
            "Epoch: 229, Avg loss: 0.3013265248388052\n",
            "Epoch: 230, Avg loss: 0.3000170789193362\n",
            "Epoch: 231, Avg loss: 0.2996283421292901\n",
            "Epoch: 232, Avg loss: 0.2989549298305064\n",
            "Epoch: 233, Avg loss: 0.30041552195325494\n",
            "Epoch: 234, Avg loss: 0.2996149043552577\n",
            "Epoch: 235, Avg loss: 0.29984366735443474\n",
            "Epoch: 236, Avg loss: 0.30049701752141117\n",
            "Epoch: 237, Avg loss: 0.2998345226980746\n",
            "Epoch: 238, Avg loss: 0.29921155804768207\n",
            "Epoch: 239, Avg loss: 0.3021166958846152\n",
            "Epoch: 240, Avg loss: 0.29993084343150256\n",
            "Epoch: 241, Avg loss: 0.2993767635896802\n",
            "Epoch: 242, Avg loss: 0.30005153762176634\n",
            "Epoch: 243, Avg loss: 0.3002717566676438\n",
            "Epoch: 244, Avg loss: 0.30027362098917365\n",
            "Epoch: 245, Avg loss: 0.2998802629299462\n",
            "Epoch: 246, Avg loss: 0.3001268756575882\n",
            "Epoch: 247, Avg loss: 0.3002503761090338\n",
            "Epoch: 248, Avg loss: 0.2998937388882041\n",
            "Epoch: 249, Avg loss: 0.30035942438989877\n",
            "Epoch: 250, Avg loss: 0.2995641535148025\n",
            "Epoch: 251, Avg loss: 0.3004231697879732\n",
            "Epoch: 252, Avg loss: 0.30079049784690143\n",
            "Epoch: 253, Avg loss: 0.2990129703655839\n",
            "Epoch: 254, Avg loss: 0.3003642656840384\n",
            "Epoch: 255, Avg loss: 0.30147198867052794\n",
            "Epoch: 256, Avg loss: 0.3007151516154408\n",
            "Epoch: 257, Avg loss: 0.3004065006505698\n",
            "Epoch: 258, Avg loss: 0.30050877360627054\n",
            "Epoch: 259, Avg loss: 0.299733848311007\n",
            "Epoch: 260, Avg loss: 0.3008978203870356\n",
            "Epoch: 261, Avg loss: 0.2996743952855468\n",
            "Epoch: 262, Avg loss: 0.3001149891875684\n",
            "Epoch: 263, Avg loss: 0.29994554156437514\n",
            "Epoch: 264, Avg loss: 0.30138291195034983\n",
            "Epoch: 265, Avg loss: 0.3006490814499557\n",
            "Epoch: 266, Avg loss: 0.2989706415683031\n",
            "Epoch: 267, Avg loss: 0.298881701938808\n",
            "Epoch: 268, Avg loss: 0.30081375488080087\n",
            "Epoch: 269, Avg loss: 0.3004549369215965\n",
            "Epoch: 270, Avg loss: 0.3000952948816121\n",
            "Epoch: 271, Avg loss: 0.29969457145780326\n",
            "Epoch: 272, Avg loss: 0.2999894317239523\n",
            "Epoch: 273, Avg loss: 0.29927894375286995\n",
            "Epoch: 274, Avg loss: 0.29990506153553725\n",
            "Epoch: 275, Avg loss: 0.29879417549818754\n",
            "Epoch: 276, Avg loss: 0.3004299882799387\n",
            "Epoch: 277, Avg loss: 0.29964842163026334\n",
            "Epoch: 278, Avg loss: 0.2990947035141289\n",
            "Epoch: 279, Avg loss: 0.3010083924978971\n",
            "Epoch: 280, Avg loss: 0.2993246082682163\n",
            "Epoch: 281, Avg loss: 0.3010784928686917\n",
            "Epoch: 282, Avg loss: 0.30053737899288535\n",
            "Epoch: 283, Avg loss: 0.2996879929676652\n",
            "Epoch: 284, Avg loss: 0.30114789828658106\n",
            "Epoch: 285, Avg loss: 0.2986596983857453\n",
            "Epoch: 286, Avg loss: 0.29948696214705706\n",
            "Epoch: 287, Avg loss: 0.2997534340247512\n",
            "Epoch: 288, Avg loss: 0.2997619777917862\n",
            "Epoch: 289, Avg loss: 0.3010776750743389\n",
            "Epoch: 290, Avg loss: 0.3006076455116272\n",
            "Epoch: 291, Avg loss: 0.2999593541957438\n",
            "Epoch: 292, Avg loss: 0.3010641922242939\n",
            "Epoch: 293, Avg loss: 0.2986331040970981\n",
            "Epoch: 294, Avg loss: 0.2993454813025892\n",
            "Epoch: 295, Avg loss: 0.2985922967083752\n",
            "Epoch: 296, Avg loss: 0.3000490179285407\n",
            "Epoch: 297, Avg loss: 0.29857170321047305\n",
            "Epoch: 298, Avg loss: 0.2999561448581517\n",
            "Epoch: 299, Avg loss: 0.2990416078828275\n",
            "Epoch: 300, Avg loss: 0.30082354387268423\n",
            "Epoch: 301, Avg loss: 0.29838562328368423\n",
            "Epoch: 302, Avg loss: 0.29989719595760106\n",
            "Epoch: 303, Avg loss: 0.2985183781944215\n",
            "Epoch: 304, Avg loss: 0.29917328506708146\n",
            "Epoch: 305, Avg loss: 0.30016863346099854\n",
            "Epoch: 306, Avg loss: 0.30023344745859504\n",
            "Epoch: 307, Avg loss: 0.29904735926538706\n",
            "Epoch: 308, Avg loss: 0.29926777840591967\n",
            "Epoch: 309, Avg loss: 0.2992912587709725\n",
            "Epoch: 310, Avg loss: 0.2991239379160106\n",
            "Epoch: 311, Avg loss: 0.2992155780084431\n",
            "Epoch: 312, Avg loss: 0.3000879901461303\n",
            "Epoch: 313, Avg loss: 0.2995169799774885\n",
            "Epoch: 314, Avg loss: 0.2997690201271325\n",
            "Epoch: 315, Avg loss: 0.2997960024513304\n",
            "Epoch: 316, Avg loss: 0.29999795500189064\n",
            "Epoch: 317, Avg loss: 0.29966224543750286\n",
            "Epoch: 318, Avg loss: 0.29919587513431906\n",
            "Epoch: 319, Avg loss: 0.3005331765860319\n",
            "Epoch: 320, Avg loss: 0.2986270137131214\n",
            "Epoch: 321, Avg loss: 0.30032428512349724\n",
            "Epoch: 322, Avg loss: 0.2987013516947627\n",
            "Epoch: 323, Avg loss: 0.29975097021088004\n",
            "Epoch: 324, Avg loss: 0.2996007176116109\n",
            "Epoch: 325, Avg loss: 0.29941405802965165\n",
            "Epoch: 326, Avg loss: 0.2991024011746049\n",
            "Epoch: 327, Avg loss: 0.29971566097810864\n",
            "Epoch: 328, Avg loss: 0.2991156877949834\n",
            "Epoch: 329, Avg loss: 0.3011797131970525\n",
            "Epoch: 330, Avg loss: 0.29952601408585905\n",
            "Epoch: 331, Avg loss: 0.29856381034478546\n",
            "Epoch: 332, Avg loss: 0.3010882494039834\n",
            "Epoch: 333, Avg loss: 0.2997206442989409\n",
            "Epoch: 334, Avg loss: 0.30087896501645445\n",
            "Epoch: 335, Avg loss: 0.30016196775250137\n",
            "Epoch: 336, Avg loss: 0.29932755874469874\n",
            "Epoch: 337, Avg loss: 0.29868621239438653\n",
            "Epoch: 338, Avg loss: 0.2985930901952088\n",
            "Epoch: 339, Avg loss: 0.29907124675810337\n",
            "Epoch: 340, Avg loss: 0.30052166525274515\n",
            "Epoch: 341, Avg loss: 0.2994277149438858\n",
            "Epoch: 342, Avg loss: 0.29977496759966016\n",
            "Epoch: 343, Avg loss: 0.3007489492185414\n",
            "Epoch: 344, Avg loss: 0.2987784191034734\n",
            "Epoch: 345, Avg loss: 0.29953042110428213\n",
            "Epoch: 346, Avg loss: 0.29957690252922475\n",
            "Epoch: 347, Avg loss: 0.29925919277593493\n",
            "Epoch: 348, Avg loss: 0.298789388500154\n",
            "Epoch: 349, Avg loss: 0.29987369012087584\n",
            "Epoch: 350, Avg loss: 0.29867845280095934\n",
            "Epoch: 351, Avg loss: 0.2987781044095755\n",
            "Epoch: 352, Avg loss: 0.299833205062896\n",
            "Epoch: 353, Avg loss: 0.2997837648727\n",
            "Epoch: 354, Avg loss: 0.29912706799805167\n",
            "Epoch: 355, Avg loss: 0.2990667408332229\n",
            "Epoch: 356, Avg loss: 0.2990952076390386\n",
            "Epoch: 357, Avg loss: 0.2992094009183347\n",
            "Epoch: 358, Avg loss: 0.2991395079996437\n",
            "Epoch: 359, Avg loss: 0.2999287560582161\n",
            "Epoch: 360, Avg loss: 0.2980579731054604\n",
            "Epoch: 361, Avg loss: 0.2976030599325895\n",
            "Epoch: 362, Avg loss: 0.29874230455607176\n",
            "Epoch: 363, Avg loss: 0.29849074874073267\n",
            "Epoch: 364, Avg loss: 0.29896734971553085\n",
            "Epoch: 365, Avg loss: 0.2990113066509366\n",
            "Epoch: 366, Avg loss: 0.2987968482077122\n",
            "Epoch: 367, Avg loss: 0.3002039077691734\n",
            "Epoch: 368, Avg loss: 0.29909297786653044\n",
            "Epoch: 369, Avg loss: 0.2989659009501338\n",
            "Epoch: 370, Avg loss: 0.29830535016953946\n",
            "Epoch: 371, Avg loss: 0.29996591452509164\n",
            "Epoch: 372, Avg loss: 0.29908659057691694\n",
            "Epoch: 373, Avg loss: 0.29737822748720644\n",
            "Epoch: 374, Avg loss: 0.3001652632839978\n",
            "Epoch: 375, Avg loss: 0.2989467357285321\n",
            "Epoch: 376, Avg loss: 0.2994282113388181\n",
            "Epoch: 377, Avg loss: 0.2984676336869597\n",
            "Epoch: 378, Avg loss: 0.29855183297768234\n",
            "Epoch: 379, Avg loss: 0.298345248028636\n",
            "Epoch: 380, Avg loss: 0.29871779261156917\n",
            "Epoch: 381, Avg loss: 0.3007405145093799\n",
            "Epoch: 382, Avg loss: 0.2991809888742864\n",
            "Epoch: 383, Avg loss: 0.29916151678189634\n",
            "Epoch: 384, Avg loss: 0.3006191221065819\n",
            "Epoch: 385, Avg loss: 0.29922028742730616\n",
            "Epoch: 386, Avg loss: 0.2986868845298886\n",
            "Epoch: 387, Avg loss: 0.29983573900535704\n",
            "Epoch: 388, Avg loss: 0.299260131129995\n",
            "Epoch: 389, Avg loss: 0.29911003466695546\n",
            "Epoch: 390, Avg loss: 0.2985278981737792\n",
            "Epoch: 391, Avg loss: 0.30093701407313345\n",
            "Epoch: 392, Avg loss: 0.29992529391311107\n",
            "Epoch: 393, Avg loss: 0.2985134071670473\n",
            "Epoch: 394, Avg loss: 0.29834606386721135\n",
            "Epoch: 395, Avg loss: 0.3015712765045464\n",
            "Epoch: 396, Avg loss: 0.2982180092483759\n",
            "Epoch: 397, Avg loss: 0.29938217825256286\n",
            "Epoch: 398, Avg loss: 0.2978661055676639\n",
            "Epoch: 399, Avg loss: 0.2986987271346152\n",
            "Epoch: 400, Avg loss: 0.3007407728116959\n",
            "Epoch: 401, Avg loss: 0.2986566362902522\n",
            "Epoch: 402, Avg loss: 0.29976363824680446\n",
            "Epoch: 403, Avg loss: 0.2995173825882375\n",
            "Epoch: 404, Avg loss: 0.30011043772101403\n",
            "Epoch: 405, Avg loss: 0.2986815164797008\n",
            "Epoch: 406, Avg loss: 0.30024078534916043\n",
            "Epoch: 407, Avg loss: 0.2987438895739615\n",
            "Epoch: 408, Avg loss: 0.2982699770480394\n",
            "Epoch: 409, Avg loss: 0.2995529182255268\n",
            "Epoch: 410, Avg loss: 0.299025119561702\n",
            "Epoch: 411, Avg loss: 0.2995325949974358\n",
            "Epoch: 412, Avg loss: 0.29952573431655766\n",
            "Epoch: 413, Avg loss: 0.2988270462490618\n",
            "Epoch: 414, Avg loss: 0.2992235543206334\n",
            "Epoch: 415, Avg loss: 0.29871439598500726\n",
            "Epoch: 416, Avg loss: 0.29919212255626915\n",
            "Epoch: 417, Avg loss: 0.2984570383094251\n",
            "Epoch: 418, Avg loss: 0.29835321865975856\n",
            "Epoch: 419, Avg loss: 0.30052684880793096\n",
            "Epoch: 420, Avg loss: 0.2987322064116597\n",
            "Epoch: 421, Avg loss: 0.29901615316048263\n",
            "Epoch: 422, Avg loss: 0.30004363413900137\n",
            "Epoch: 423, Avg loss: 0.29840045599266884\n",
            "Epoch: 424, Avg loss: 0.2996759430505335\n",
            "Epoch: 425, Avg loss: 0.2984648358076811\n",
            "Epoch: 426, Avg loss: 0.29958055214956403\n",
            "Epoch: 427, Avg loss: 0.29882210716605184\n",
            "Epoch: 428, Avg loss: 0.2983342004008591\n",
            "Epoch: 429, Avg loss: 0.2994405446574092\n",
            "Epoch: 430, Avg loss: 0.29798648580908776\n",
            "Epoch: 431, Avg loss: 0.2993991956114769\n",
            "Epoch: 432, Avg loss: 0.29859890998341143\n",
            "Epoch: 433, Avg loss: 0.2980264347046614\n",
            "Epoch: 434, Avg loss: 0.29853583723306654\n",
            "Epoch: 435, Avg loss: 0.3004729012027383\n",
            "Epoch: 436, Avg loss: 0.29824628168717027\n",
            "Epoch: 437, Avg loss: 0.2989623516332358\n",
            "Epoch: 438, Avg loss: 0.2990618674084544\n",
            "Epoch: 439, Avg loss: 0.2988411718979478\n",
            "Epoch: 440, Avg loss: 0.29882457428611814\n",
            "Epoch: 441, Avg loss: 0.2980773149989545\n",
            "Epoch: 442, Avg loss: 0.29936394589021803\n",
            "Epoch: 443, Avg loss: 0.297801006026566\n",
            "Epoch: 444, Avg loss: 0.29997860845178365\n",
            "Epoch: 445, Avg loss: 0.29797592042014004\n",
            "Epoch: 446, Avg loss: 0.298938695108518\n",
            "Epoch: 447, Avg loss: 0.29900279650464656\n",
            "Epoch: 448, Avg loss: 0.2990551793947816\n",
            "Epoch: 449, Avg loss: 0.29929353543557224\n",
            "Epoch: 450, Avg loss: 0.2992788736242801\n",
            "Epoch: 451, Avg loss: 0.29923271061852574\n",
            "Epoch: 452, Avg loss: 0.2978760435245931\n",
            "Epoch: 453, Avg loss: 0.2981024323031306\n",
            "Epoch: 454, Avg loss: 0.2995124030858278\n",
            "Epoch: 455, Avg loss: 0.29847890287637713\n",
            "Epoch: 456, Avg loss: 0.2986337776761502\n",
            "Epoch: 457, Avg loss: 0.29867586232721804\n",
            "Epoch: 458, Avg loss: 0.29743563309311866\n",
            "Epoch: 459, Avg loss: 0.29956019734963774\n",
            "Epoch: 460, Avg loss: 0.29804025366902354\n",
            "Epoch: 461, Avg loss: 0.2994049371685833\n",
            "Epoch: 462, Avg loss: 0.29931302173063157\n",
            "Epoch: 463, Avg loss: 0.29784981003031136\n",
            "Epoch: 464, Avg loss: 0.29906649719923734\n",
            "Epoch: 465, Avg loss: 0.29906652187928556\n",
            "Epoch: 466, Avg loss: 0.29933900842443106\n",
            "Epoch: 467, Avg loss: 0.300725784804672\n",
            "Epoch: 468, Avg loss: 0.29758702432736756\n",
            "Epoch: 469, Avg loss: 0.29850815730169417\n",
            "Epoch: 470, Avg loss: 0.298915484524332\n",
            "Epoch: 471, Avg loss: 0.2978132198564708\n",
            "Epoch: 472, Avg loss: 0.2995892331935465\n",
            "Epoch: 473, Avg loss: 0.2984952187165618\n",
            "Epoch: 474, Avg loss: 0.29805369237437845\n",
            "Epoch: 475, Avg loss: 0.29918627655133606\n",
            "Epoch: 476, Avg loss: 0.2985496921464801\n",
            "Epoch: 477, Avg loss: 0.2991991901770234\n",
            "Epoch: 478, Avg loss: 0.2998708801344037\n",
            "Epoch: 479, Avg loss: 0.29814690502826124\n",
            "Epoch: 480, Avg loss: 0.3002400924451649\n",
            "Epoch: 481, Avg loss: 0.29835680248215796\n",
            "Epoch: 482, Avg loss: 0.29927560677751897\n",
            "Epoch: 483, Avg loss: 0.2969252889044583\n",
            "Epoch: 484, Avg loss: 0.29798269402235744\n",
            "Epoch: 485, Avg loss: 0.29980376483872534\n",
            "Epoch: 486, Avg loss: 0.29948264504782857\n",
            "Epoch: 487, Avg loss: 0.2987937189638615\n",
            "Epoch: 488, Avg loss: 0.2974326562136412\n",
            "Epoch: 489, Avg loss: 0.29953902242705227\n",
            "Epoch: 490, Avg loss: 0.29848203491419556\n",
            "Epoch: 491, Avg loss: 0.29840057622641325\n",
            "Epoch: 492, Avg loss: 0.2982392503879964\n",
            "Epoch: 493, Avg loss: 0.2985177646391094\n",
            "Epoch: 494, Avg loss: 0.2993480031378567\n",
            "Epoch: 495, Avg loss: 0.29930861443281176\n",
            "Epoch: 496, Avg loss: 0.2981442232616246\n",
            "Epoch: 497, Avg loss: 0.2977137427777052\n",
            "Epoch: 498, Avg loss: 0.3004689829424024\n",
            "Epoch: 499, Avg loss: 0.2979590339586139\n",
            "Epoch: 500, Avg loss: 0.2971383348107338\n",
            "Epoch: 501, Avg loss: 0.29883964397013185\n",
            "Epoch: 502, Avg loss: 0.2980507681146264\n",
            "Epoch: 503, Avg loss: 0.2984559640288353\n",
            "Epoch: 504, Avg loss: 0.2973424134775996\n",
            "Epoch: 505, Avg loss: 0.30145051088184116\n",
            "Epoch: 506, Avg loss: 0.29868837371468543\n",
            "Epoch: 507, Avg loss: 0.29914950085803865\n",
            "Epoch: 508, Avg loss: 0.2979344271123409\n",
            "Epoch: 509, Avg loss: 0.2994794262573123\n",
            "Epoch: 510, Avg loss: 0.29777431264519694\n",
            "Epoch: 511, Avg loss: 0.2992150974459946\n",
            "Epoch: 512, Avg loss: 0.2980313121341169\n",
            "Epoch: 513, Avg loss: 0.29788213558495047\n",
            "Epoch: 514, Avg loss: 0.29996074717491866\n",
            "Epoch: 515, Avg loss: 0.29910067562013865\n",
            "Epoch: 516, Avg loss: 0.299053693190217\n",
            "Epoch: 517, Avg loss: 0.29887631265446546\n",
            "Epoch: 518, Avg loss: 0.29833394261077045\n",
            "Epoch: 519, Avg loss: 0.2993870352394879\n",
            "Epoch: 520, Avg loss: 0.29760652491822837\n",
            "Epoch: 521, Avg loss: 0.29817539770156143\n",
            "Epoch: 522, Avg loss: 0.29868581499904395\n",
            "Epoch: 523, Avg loss: 0.29951885174959897\n",
            "Epoch: 524, Avg loss: 0.29803775195032356\n",
            "Epoch: 525, Avg loss: 0.29880382101982833\n",
            "Epoch: 526, Avg loss: 0.2984461495652795\n",
            "Epoch: 527, Avg loss: 0.2996273783035576\n",
            "Epoch: 528, Avg loss: 0.29959793845191596\n",
            "Epoch: 529, Avg loss: 0.298483513109386\n",
            "Epoch: 530, Avg loss: 0.29769109999760984\n",
            "Epoch: 531, Avg loss: 0.29916027644649146\n",
            "Epoch: 532, Avg loss: 0.29727306105196477\n",
            "Epoch: 533, Avg loss: 0.2977580660022795\n",
            "Epoch: 534, Avg loss: 0.2988246325403452\n",
            "Epoch: 535, Avg loss: 0.29783885879442096\n",
            "Epoch: 536, Avg loss: 0.2988867181818932\n",
            "Epoch: 537, Avg loss: 0.2984686212614179\n",
            "Epoch: 538, Avg loss: 0.2986809339374304\n",
            "Epoch: 539, Avg loss: 0.29759779991582036\n",
            "Epoch: 540, Avg loss: 0.2989135001786053\n",
            "Epoch: 541, Avg loss: 0.2980507989414036\n",
            "Epoch: 542, Avg loss: 0.29837337844073775\n",
            "Epoch: 543, Avg loss: 0.29794823490083217\n",
            "Epoch: 544, Avg loss: 0.2983780849725008\n",
            "Epoch: 545, Avg loss: 0.29943291200324895\n",
            "Epoch: 546, Avg loss: 0.29956925446167587\n",
            "Epoch: 547, Avg loss: 0.2983601937070489\n",
            "Epoch: 548, Avg loss: 0.29846843555569647\n",
            "Epoch: 549, Avg loss: 0.2988578578457236\n",
            "Epoch: 550, Avg loss: 0.2983823066577315\n",
            "Epoch: 551, Avg loss: 0.29751760615035894\n",
            "Epoch: 552, Avg loss: 0.29817524990066885\n",
            "Epoch: 553, Avg loss: 0.2989692925475538\n",
            "Epoch: 554, Avg loss: 0.29823765316978096\n",
            "Epoch: 555, Avg loss: 0.2981834406964481\n",
            "Epoch: 556, Avg loss: 0.29875703183934094\n",
            "Epoch: 557, Avg loss: 0.29802660467103126\n",
            "Epoch: 558, Avg loss: 0.2979997958987951\n",
            "Epoch: 559, Avg loss: 0.2987321628257632\n",
            "Epoch: 560, Avg loss: 0.29721642946824434\n",
            "Epoch: 561, Avg loss: 0.2984516422264278\n",
            "Epoch: 562, Avg loss: 0.2991360854357481\n",
            "Epoch: 563, Avg loss: 0.29906281931325795\n",
            "Epoch: 564, Avg loss: 0.2987098526209593\n",
            "Epoch: 565, Avg loss: 0.2990588262677193\n",
            "Epoch: 566, Avg loss: 0.2980679246596992\n",
            "Epoch: 567, Avg loss: 0.2981038775295019\n",
            "Epoch: 568, Avg loss: 0.3003570534288883\n",
            "Epoch: 569, Avg loss: 0.2979476833716035\n",
            "Epoch: 570, Avg loss: 0.29760140292346476\n",
            "Epoch: 571, Avg loss: 0.29861213485710325\n",
            "Epoch: 572, Avg loss: 0.2978144011460245\n",
            "Epoch: 573, Avg loss: 0.2994345257990062\n",
            "Epoch: 574, Avg loss: 0.29892025254666804\n",
            "Epoch: 575, Avg loss: 0.29852376207709314\n",
            "Epoch: 576, Avg loss: 0.29826936246827246\n",
            "Epoch: 577, Avg loss: 0.3001740955747664\n",
            "Epoch: 578, Avg loss: 0.2999450409784913\n",
            "Epoch: 579, Avg loss: 0.297951256390661\n",
            "Epoch: 580, Avg loss: 0.29847109615802764\n",
            "Epoch: 581, Avg loss: 0.2978711239993572\n",
            "Epoch: 582, Avg loss: 0.2985893410630524\n",
            "Epoch: 583, Avg loss: 0.2974936067126691\n",
            "Epoch: 584, Avg loss: 0.2993384222500026\n",
            "Epoch: 585, Avg loss: 0.2977484665811062\n",
            "Epoch: 586, Avg loss: 0.3006214668042958\n",
            "Epoch: 587, Avg loss: 0.2992356188595295\n",
            "Epoch: 588, Avg loss: 0.29750969596207144\n",
            "Epoch: 589, Avg loss: 0.29792136983014644\n",
            "Epoch: 590, Avg loss: 0.2981269706506282\n",
            "Epoch: 591, Avg loss: 0.2978680868633091\n",
            "Epoch: 592, Avg loss: 0.2972746673971415\n",
            "Epoch: 593, Avg loss: 0.29943063620012256\n",
            "Epoch: 594, Avg loss: 0.29802910713478925\n",
            "Epoch: 595, Avg loss: 0.2975791092962027\n",
            "Epoch: 596, Avg loss: 0.298573908675462\n",
            "Epoch: 597, Avg loss: 0.29769557546824216\n",
            "Epoch: 598, Avg loss: 0.2980544488877058\n",
            "Epoch: 599, Avg loss: 0.2975590199697763\n",
            "Epoch: 600, Avg loss: 0.2983043447136879\n",
            "Epoch: 601, Avg loss: 0.2981890651397407\n",
            "Epoch: 602, Avg loss: 0.29920797869563104\n",
            "Epoch: 603, Avg loss: 0.2990939039736986\n",
            "Epoch: 604, Avg loss: 0.2987546813674271\n",
            "Epoch: 605, Avg loss: 0.2978551723994315\n",
            "Epoch: 606, Avg loss: 0.29747621854767203\n",
            "Epoch: 607, Avg loss: 0.29984532920643686\n",
            "Epoch: 608, Avg loss: 0.3001636780798435\n",
            "Epoch: 609, Avg loss: 0.29737731353379787\n",
            "Epoch: 610, Avg loss: 0.29836236862465737\n",
            "Epoch: 611, Avg loss: 0.3005724842660129\n",
            "Epoch: 612, Avg loss: 0.29881070014089345\n",
            "Epoch: 613, Avg loss: 0.29903483763337135\n",
            "Epoch: 614, Avg loss: 0.29786369800567625\n",
            "Epoch: 615, Avg loss: 0.2976565735414624\n",
            "Epoch: 616, Avg loss: 0.29748322889208795\n",
            "Epoch: 617, Avg loss: 0.29848622232675553\n",
            "Epoch: 618, Avg loss: 0.298490050714463\n",
            "Epoch: 619, Avg loss: 0.29775274032726884\n",
            "Epoch: 620, Avg loss: 0.29911102149635554\n",
            "Epoch: 621, Avg loss: 0.2982200073078275\n",
            "Epoch: 622, Avg loss: 0.29859346374869344\n",
            "Epoch: 623, Avg loss: 0.2990453545004129\n",
            "Epoch: 624, Avg loss: 0.29745194800198077\n",
            "Epoch: 625, Avg loss: 0.2993845123797655\n",
            "Epoch: 626, Avg loss: 0.29750846046954393\n",
            "Epoch: 627, Avg loss: 0.29844393860548735\n",
            "Epoch: 628, Avg loss: 0.29707004223018885\n",
            "Epoch: 629, Avg loss: 0.2969265969935805\n",
            "Epoch: 630, Avg loss: 0.30021647540852425\n",
            "Epoch: 631, Avg loss: 0.2985199522227049\n",
            "Epoch: 632, Avg loss: 0.29801654973998665\n",
            "Epoch: 633, Avg loss: 0.2978254630230367\n",
            "Epoch: 634, Avg loss: 0.2972219312563539\n",
            "Epoch: 635, Avg loss: 0.2974445655010641\n",
            "Epoch: 636, Avg loss: 0.2974788430146873\n",
            "Epoch: 637, Avg loss: 0.2976206799969077\n",
            "Epoch: 638, Avg loss: 0.29800266278907656\n",
            "Epoch: 639, Avg loss: 0.29768142933025954\n",
            "Epoch: 640, Avg loss: 0.29692379091866317\n",
            "Epoch: 641, Avg loss: 0.2990793171338737\n",
            "Epoch: 642, Avg loss: 0.2974073616787791\n",
            "Epoch: 643, Avg loss: 0.29798466274514795\n",
            "Epoch: 644, Avg loss: 0.2985874551348388\n",
            "Epoch: 645, Avg loss: 0.29758454831317066\n",
            "Epoch: 646, Avg loss: 0.29778423998504877\n",
            "Epoch: 647, Avg loss: 0.29976988965645435\n",
            "Epoch: 648, Avg loss: 0.29737829575315117\n",
            "Epoch: 649, Avg loss: 0.29782783444970845\n",
            "Epoch: 650, Avg loss: 0.29869904853403567\n",
            "Epoch: 651, Avg loss: 0.2992238071747124\n",
            "Epoch: 652, Avg loss: 0.2972787728533149\n",
            "Epoch: 653, Avg loss: 0.29890979938209056\n",
            "Epoch: 654, Avg loss: 0.29749586563557384\n",
            "Epoch: 655, Avg loss: 0.29960004054009914\n",
            "Epoch: 656, Avg loss: 0.29914726708084344\n",
            "Epoch: 657, Avg loss: 0.2984810282476246\n",
            "Epoch: 658, Avg loss: 0.29860082515515385\n",
            "Epoch: 659, Avg loss: 0.2982472004368901\n",
            "Epoch: 660, Avg loss: 0.296924801170826\n",
            "Epoch: 661, Avg loss: 0.29827721873298285\n",
            "Epoch: 662, Avg loss: 0.29886143617331984\n",
            "Epoch: 663, Avg loss: 0.2978815660811961\n",
            "Epoch: 664, Avg loss: 0.2974029125645757\n",
            "Epoch: 665, Avg loss: 0.29821926821023226\n",
            "Epoch: 666, Avg loss: 0.29798141997307537\n",
            "Epoch: 667, Avg loss: 0.29789511850103734\n",
            "Epoch: 668, Avg loss: 0.2976368172094226\n",
            "Epoch: 669, Avg loss: 0.29710146235302093\n",
            "Epoch: 670, Avg loss: 0.2993552092462778\n",
            "Epoch: 671, Avg loss: 0.29774415753781797\n",
            "Epoch: 672, Avg loss: 0.29849422741681336\n",
            "Epoch: 673, Avg loss: 0.2980393398553133\n",
            "Epoch: 674, Avg loss: 0.29922229405492545\n",
            "Epoch: 675, Avg loss: 0.2972800960764289\n",
            "Epoch: 676, Avg loss: 0.2978201896883547\n",
            "Epoch: 677, Avg loss: 0.29742846451699734\n",
            "Epoch: 678, Avg loss: 0.29749185335822403\n",
            "Epoch: 679, Avg loss: 0.2978280819021165\n",
            "Epoch: 680, Avg loss: 0.29796501128003\n",
            "Epoch: 681, Avg loss: 0.29714214876294137\n",
            "Epoch: 682, Avg loss: 0.2974597563035786\n",
            "Epoch: 683, Avg loss: 0.296810853574425\n",
            "Epoch: 684, Avg loss: 0.29809848191216587\n",
            "Epoch: 685, Avg loss: 0.29775402657687666\n",
            "Epoch: 686, Avg loss: 0.30035957423970105\n",
            "Epoch: 687, Avg loss: 0.29823217187076806\n",
            "Epoch: 688, Avg loss: 0.29764830209314824\n",
            "Epoch: 689, Avg loss: 0.2977523682639003\n",
            "Epoch: 690, Avg loss: 0.29836546699516475\n",
            "Epoch: 691, Avg loss: 0.29725519185885785\n",
            "Epoch: 692, Avg loss: 0.2988444075919688\n",
            "Epoch: 693, Avg loss: 0.2977531709708273\n",
            "Epoch: 694, Avg loss: 0.2982155891135335\n",
            "Epoch: 695, Avg loss: 0.2992684295400977\n",
            "Epoch: 696, Avg loss: 0.2980411972850561\n",
            "Epoch: 697, Avg loss: 0.2978897853754461\n",
            "Epoch: 698, Avg loss: 0.2969888564199209\n",
            "Epoch: 699, Avg loss: 0.29766233209520576\n",
            "Epoch: 700, Avg loss: 0.29732896452769636\n",
            "Epoch: 701, Avg loss: 0.2978120854124427\n",
            "Epoch: 702, Avg loss: 0.2966935962438583\n",
            "Epoch: 703, Avg loss: 0.29869326688349246\n",
            "Epoch: 704, Avg loss: 0.29763280488550664\n",
            "Epoch: 705, Avg loss: 0.2989058499224484\n",
            "Epoch: 706, Avg loss: 0.2982468054629862\n",
            "Epoch: 707, Avg loss: 0.29689141530543567\n",
            "Epoch: 708, Avg loss: 0.298013121355325\n",
            "Epoch: 709, Avg loss: 0.29861824959516525\n",
            "Epoch: 710, Avg loss: 0.29745280984789135\n",
            "Epoch: 711, Avg loss: 0.29919501608237625\n",
            "Epoch: 712, Avg loss: 0.29806594820693133\n",
            "Epoch: 713, Avg loss: 0.2986332654953003\n",
            "Epoch: 714, Avg loss: 0.297308711335063\n",
            "Epoch: 715, Avg loss: 0.2975958946160972\n",
            "Epoch: 716, Avg loss: 0.2981291912961751\n",
            "Epoch: 717, Avg loss: 0.2983173090964556\n",
            "Epoch: 718, Avg loss: 0.2974081565160304\n",
            "Epoch: 719, Avg loss: 0.2979999686125666\n",
            "Epoch: 720, Avg loss: 0.2974106205627322\n",
            "Epoch: 721, Avg loss: 0.29788679694756864\n",
            "Epoch: 722, Avg loss: 0.296829754114151\n",
            "Epoch: 723, Avg loss: 0.2976491417735815\n",
            "Epoch: 724, Avg loss: 0.2992197072133422\n",
            "Epoch: 725, Avg loss: 0.2983715819194913\n",
            "Epoch: 726, Avg loss: 0.2975799301639199\n",
            "Epoch: 727, Avg loss: 0.2978749142959714\n",
            "Epoch: 728, Avg loss: 0.29787584152072666\n",
            "Epoch: 729, Avg loss: 0.2993526063859463\n",
            "Epoch: 730, Avg loss: 0.29742407919839026\n",
            "Epoch: 731, Avg loss: 0.29929483886808156\n",
            "Epoch: 732, Avg loss: 0.2981306095607579\n",
            "Epoch: 733, Avg loss: 0.298135095462203\n",
            "Epoch: 734, Avg loss: 0.29819630095735195\n",
            "Epoch: 735, Avg loss: 0.2985935871489346\n",
            "Epoch: 736, Avg loss: 0.2971137881278992\n",
            "Epoch: 737, Avg loss: 0.2969577337615192\n",
            "Epoch: 738, Avg loss: 0.297067479416728\n",
            "Epoch: 739, Avg loss: 0.29776047812774775\n",
            "Epoch: 740, Avg loss: 0.2969402148388326\n",
            "Epoch: 741, Avg loss: 0.29709654496982696\n",
            "Epoch: 742, Avg loss: 0.2987059083767235\n",
            "Epoch: 743, Avg loss: 0.29757243357598784\n",
            "Epoch: 744, Avg loss: 0.2966771384701133\n",
            "Epoch: 745, Avg loss: 0.2971449068747461\n",
            "Epoch: 746, Avg loss: 0.2986097939312458\n",
            "Epoch: 747, Avg loss: 0.29724978990852835\n",
            "Epoch: 748, Avg loss: 0.29775808649137614\n",
            "Epoch: 749, Avg loss: 0.2974955257959664\n",
            "Epoch: 750, Avg loss: 0.2990440768189728\n",
            "Epoch: 751, Avg loss: 0.2975248453207314\n",
            "Epoch: 752, Avg loss: 0.29821074157953265\n",
            "Epoch: 753, Avg loss: 0.29838109901174903\n",
            "Epoch: 754, Avg loss: 0.2982630872167647\n",
            "Epoch: 755, Avg loss: 0.29720148709602656\n",
            "Epoch: 756, Avg loss: 0.2982009768486023\n",
            "Epoch: 757, Avg loss: 0.2978417228907347\n",
            "Epoch: 758, Avg loss: 0.2969264761544764\n",
            "Epoch: 759, Avg loss: 0.29804231189191344\n",
            "Epoch: 760, Avg loss: 0.29750888608396053\n",
            "Epoch: 761, Avg loss: 0.2971480272244662\n",
            "Epoch: 762, Avg loss: 0.29793484397232534\n",
            "Epoch: 763, Avg loss: 0.2971518971025944\n",
            "Epoch: 764, Avg loss: 0.29781583044677973\n",
            "Epoch: 765, Avg loss: 0.2981006072834134\n",
            "Epoch: 766, Avg loss: 0.2966960182413459\n",
            "Epoch: 767, Avg loss: 0.29783084243535995\n",
            "Epoch: 768, Avg loss: 0.2987632638774812\n",
            "Epoch: 769, Avg loss: 0.29743059258908033\n",
            "Epoch: 770, Avg loss: 0.297219997830689\n",
            "Epoch: 771, Avg loss: 0.297525239828974\n",
            "Epoch: 772, Avg loss: 0.2972857397980988\n",
            "Epoch: 773, Avg loss: 0.29702596701681616\n",
            "Epoch: 774, Avg loss: 0.29834704296663406\n",
            "Epoch: 775, Avg loss: 0.2991193976718932\n",
            "Epoch: 776, Avg loss: 0.2981007663533092\n",
            "Epoch: 777, Avg loss: 0.3000918078236282\n",
            "Epoch: 778, Avg loss: 0.298172961268574\n",
            "Epoch: 779, Avg loss: 0.2980382366105914\n",
            "Epoch: 780, Avg loss: 0.2976153094321489\n",
            "Epoch: 781, Avg loss: 0.2972263123840094\n",
            "Epoch: 782, Avg loss: 0.29735336611047386\n",
            "Epoch: 783, Avg loss: 0.29881032183766365\n",
            "Epoch: 784, Avg loss: 0.2974510908126831\n",
            "Epoch: 785, Avg loss: 0.29765862599015236\n",
            "Epoch: 786, Avg loss: 0.29640270611271263\n",
            "Epoch: 787, Avg loss: 0.29880542485043404\n",
            "Epoch: 788, Avg loss: 0.2999501728452742\n",
            "Epoch: 789, Avg loss: 0.2972936783917248\n",
            "Epoch: 790, Avg loss: 0.29768498302437363\n",
            "Epoch: 791, Avg loss: 0.29779564719647167\n",
            "Epoch: 792, Avg loss: 0.2972435264848173\n",
            "Epoch: 793, Avg loss: 0.2971259979531169\n",
            "Epoch: 794, Avg loss: 0.2986893185414374\n",
            "Epoch: 795, Avg loss: 0.29830928333103657\n",
            "Epoch: 796, Avg loss: 0.2973395395092666\n",
            "Epoch: 797, Avg loss: 0.29703303957358\n",
            "Epoch: 798, Avg loss: 0.2977554304525256\n",
            "Epoch: 799, Avg loss: 0.29732699240557847\n",
            "Epoch: 800, Avg loss: 0.2977027954068035\n",
            "Epoch: 801, Avg loss: 0.29749755738303063\n",
            "Epoch: 802, Avg loss: 0.2973759537562728\n",
            "Epoch: 803, Avg loss: 0.2969149867072701\n",
            "Epoch: 804, Avg loss: 0.2984868424013257\n",
            "Epoch: 805, Avg loss: 0.298377892607823\n",
            "Epoch: 806, Avg loss: 0.296792511921376\n",
            "Epoch: 807, Avg loss: 0.29719097446650267\n",
            "Epoch: 808, Avg loss: 0.29850397957488894\n",
            "Epoch: 809, Avg loss: 0.29771764473989604\n",
            "Epoch: 810, Avg loss: 0.29786948752589526\n",
            "Epoch: 811, Avg loss: 0.29736046576872466\n",
            "Epoch: 812, Avg loss: 0.29760473854839803\n",
            "Epoch: 813, Avg loss: 0.29720124024897815\n",
            "Epoch: 814, Avg loss: 0.2984675642102957\n",
            "Epoch: 815, Avg loss: 0.296934362873435\n",
            "Epoch: 816, Avg loss: 0.29840515051037075\n",
            "Epoch: 817, Avg loss: 0.2995414794422686\n",
            "Epoch: 818, Avg loss: 0.29678629925474526\n",
            "Epoch: 819, Avg loss: 0.30016967048868537\n",
            "Epoch: 820, Avg loss: 0.29821744384244087\n",
            "Epoch: 821, Avg loss: 0.2966974520124495\n",
            "Epoch: 822, Avg loss: 0.2968132719397545\n",
            "Epoch: 823, Avg loss: 0.2982619754038751\n",
            "Epoch: 824, Avg loss: 0.2964817644096911\n",
            "Epoch: 825, Avg loss: 0.29780806414783\n",
            "Epoch: 826, Avg loss: 0.29830092075280845\n",
            "Epoch: 827, Avg loss: 0.2972557513974607\n",
            "Epoch: 828, Avg loss: 0.29813238251954316\n",
            "Epoch: 829, Avg loss: 0.2964956430718303\n",
            "Epoch: 830, Avg loss: 0.2971363100223243\n",
            "Epoch: 831, Avg loss: 0.2964386556297541\n",
            "Epoch: 832, Avg loss: 0.29800780713558195\n",
            "Epoch: 833, Avg loss: 0.29776686874683944\n",
            "Epoch: 834, Avg loss: 0.29790221657603977\n",
            "Epoch: 835, Avg loss: 0.2978775014169514\n",
            "Epoch: 836, Avg loss: 0.2968758520670235\n",
            "Epoch: 837, Avg loss: 0.29787973016500474\n",
            "Epoch: 838, Avg loss: 0.2973665141500533\n",
            "Epoch: 839, Avg loss: 0.2973873716779053\n",
            "Epoch: 840, Avg loss: 0.2985743315890431\n",
            "Epoch: 841, Avg loss: 0.2985443526878953\n",
            "Epoch: 842, Avg loss: 0.29790056673809884\n",
            "Epoch: 843, Avg loss: 0.296815278660506\n",
            "Epoch: 844, Avg loss: 0.2968898043036461\n",
            "Epoch: 845, Avg loss: 0.2967806701548398\n",
            "Epoch: 846, Avg loss: 0.29800771828740835\n",
            "Epoch: 847, Avg loss: 0.29607586190104485\n",
            "Epoch: 848, Avg loss: 0.29764265157282355\n",
            "Epoch: 849, Avg loss: 0.29822017131373285\n",
            "Epoch: 850, Avg loss: 0.29729067799635234\n",
            "Epoch: 851, Avg loss: 0.29860380860045554\n",
            "Epoch: 852, Avg loss: 0.2981949013657868\n",
            "Epoch: 853, Avg loss: 0.29805144360288977\n",
            "Epoch: 854, Avg loss: 0.29856892544776203\n",
            "Epoch: 855, Avg loss: 0.2981446600519121\n",
            "Epoch: 856, Avg loss: 0.2972709150519222\n",
            "Epoch: 857, Avg loss: 0.29766312390565874\n",
            "Epoch: 858, Avg loss: 0.2973017040640116\n",
            "Epoch: 859, Avg loss: 0.29927881034091114\n",
            "Epoch: 860, Avg loss: 0.2970312811434269\n",
            "Epoch: 861, Avg loss: 0.2983585875481367\n",
            "Epoch: 862, Avg loss: 0.297296769823879\n",
            "Epoch: 863, Avg loss: 0.2968414378352463\n",
            "Epoch: 864, Avg loss: 0.2964986347593367\n",
            "Epoch: 865, Avg loss: 0.29727361984550954\n",
            "Epoch: 866, Avg loss: 0.297538947686553\n",
            "Epoch: 867, Avg loss: 0.29781962372362614\n",
            "Epoch: 868, Avg loss: 0.2986757962964475\n",
            "Epoch: 869, Avg loss: 0.29659191193059087\n",
            "Epoch: 870, Avg loss: 0.29816313125193117\n",
            "Epoch: 871, Avg loss: 0.2978037697263062\n",
            "Epoch: 872, Avg loss: 0.2975112528540194\n",
            "Epoch: 873, Avg loss: 0.29785222820937635\n",
            "Epoch: 874, Avg loss: 0.29777070675045253\n",
            "Epoch: 875, Avg loss: 0.2975017925724387\n",
            "Epoch: 876, Avg loss: 0.29800108829513194\n",
            "Epoch: 877, Avg loss: 0.2970149072818458\n",
            "Epoch: 878, Avg loss: 0.2978920848108828\n",
            "Epoch: 879, Avg loss: 0.29855658961459997\n",
            "Epoch: 880, Avg loss: 0.29826853992417457\n",
            "Epoch: 881, Avg loss: 0.29768408508971334\n",
            "Epoch: 882, Avg loss: 0.29810427175834775\n",
            "Epoch: 883, Avg loss: 0.2970896838232875\n",
            "Epoch: 884, Avg loss: 0.2965494402684271\n",
            "Epoch: 885, Avg loss: 0.29698531283065677\n",
            "Epoch: 886, Avg loss: 0.29637521551921964\n",
            "Epoch: 887, Avg loss: 0.2977709978586063\n",
            "Epoch: 888, Avg loss: 0.2967455410398543\n",
            "Epoch: 889, Avg loss: 0.2981235384941101\n",
            "Epoch: 890, Avg loss: 0.2977886592969298\n",
            "Epoch: 891, Avg loss: 0.29890927765518427\n",
            "Epoch: 892, Avg loss: 0.2983490001875907\n",
            "Epoch: 893, Avg loss: 0.2961492456495762\n",
            "Epoch: 894, Avg loss: 0.29720090748742223\n",
            "Epoch: 895, Avg loss: 0.2981855153106153\n",
            "Epoch: 896, Avg loss: 0.2979187802877277\n",
            "Epoch: 897, Avg loss: 0.2973916688002646\n",
            "Epoch: 898, Avg loss: 0.2982671929523349\n",
            "Epoch: 899, Avg loss: 0.29719813535921275\n",
            "Epoch: 900, Avg loss: 0.297470451425761\n",
            "Epoch: 901, Avg loss: 0.2965992922894657\n",
            "Epoch: 902, Avg loss: 0.29858789974823596\n",
            "Epoch: 903, Avg loss: 0.2993445660918951\n",
            "Epoch: 904, Avg loss: 0.29758993722498417\n",
            "Epoch: 905, Avg loss: 0.2967432959936559\n",
            "Epoch: 906, Avg loss: 0.29627941362559795\n",
            "Epoch: 907, Avg loss: 0.29807991134002804\n",
            "Epoch: 908, Avg loss: 0.2977604420855641\n",
            "Epoch: 909, Avg loss: 0.29929342921823265\n",
            "Epoch: 910, Avg loss: 0.2981548628769815\n",
            "Epoch: 911, Avg loss: 0.2974162939470261\n",
            "Epoch: 912, Avg loss: 0.29762146035209297\n",
            "Epoch: 913, Avg loss: 0.2975285407155752\n",
            "Epoch: 914, Avg loss: 0.29765302473679184\n",
            "Epoch: 915, Avg loss: 0.2977140355855227\n",
            "Epoch: 916, Avg loss: 0.29896633960306646\n",
            "Epoch: 917, Avg loss: 0.29631524048745633\n",
            "Epoch: 918, Avg loss: 0.29758598618209364\n",
            "Epoch: 919, Avg loss: 0.29754879474639895\n",
            "Epoch: 920, Avg loss: 0.29655243204906584\n",
            "Epoch: 921, Avg loss: 0.2970163985155523\n",
            "Epoch: 922, Avg loss: 0.2972733998671174\n",
            "Epoch: 923, Avg loss: 0.2982430006377399\n",
            "Epoch: 924, Avg loss: 0.2969694043044001\n",
            "Epoch: 925, Avg loss: 0.29640954714268447\n",
            "Epoch: 926, Avg loss: 0.2969168467447162\n",
            "Epoch: 927, Avg loss: 0.2969151438213885\n",
            "Epoch: 928, Avg loss: 0.2983243788592517\n",
            "Epoch: 929, Avg loss: 0.2988738832063973\n",
            "Epoch: 930, Avg loss: 0.29633938102051616\n",
            "Epoch: 931, Avg loss: 0.298589785117656\n",
            "Epoch: 932, Avg loss: 0.2967030432075262\n",
            "Epoch: 933, Avg loss: 0.297618889529258\n",
            "Epoch: 934, Avg loss: 0.29785355655476453\n",
            "Epoch: 935, Avg loss: 0.29757727291435004\n",
            "Epoch: 936, Avg loss: 0.2974161826074123\n",
            "Epoch: 937, Avg loss: 0.2985002426430583\n",
            "Epoch: 938, Avg loss: 0.29822644824162126\n",
            "Epoch: 939, Avg loss: 0.297512882668525\n",
            "Epoch: 940, Avg loss: 0.2976431570015848\n",
            "Epoch: 941, Avg loss: 0.29711858155205845\n",
            "Epoch: 942, Avg loss: 0.29816787168383596\n",
            "Epoch: 943, Avg loss: 0.2964845668524504\n",
            "Epoch: 944, Avg loss: 0.2987158645875752\n",
            "Epoch: 945, Avg loss: 0.2965323716402054\n",
            "Epoch: 946, Avg loss: 0.2973820362240076\n",
            "Epoch: 947, Avg loss: 0.2976017535664141\n",
            "Epoch: 948, Avg loss: 0.29692209968343375\n",
            "Epoch: 949, Avg loss: 0.2962779144756496\n",
            "Epoch: 950, Avg loss: 0.29821075974032285\n",
            "Epoch: 951, Avg loss: 0.29872162053361534\n",
            "Epoch: 952, Avg loss: 0.299026213074103\n",
            "Epoch: 953, Avg loss: 0.29735477762296797\n",
            "Epoch: 954, Avg loss: 0.296734681725502\n",
            "Epoch: 955, Avg loss: 0.2983565989881754\n",
            "Epoch: 956, Avg loss: 0.29792049042880536\n",
            "Epoch: 957, Avg loss: 0.29695492079481484\n",
            "Epoch: 958, Avg loss: 0.2965845948085189\n",
            "Epoch: 959, Avg loss: 0.29706284096464514\n",
            "Epoch: 960, Avg loss: 0.2966698705218732\n",
            "Epoch: 961, Avg loss: 0.29793293550610545\n",
            "Epoch: 962, Avg loss: 0.2973493477329612\n",
            "Epoch: 963, Avg loss: 0.2977797348983586\n",
            "Epoch: 964, Avg loss: 0.29687626352533697\n",
            "Epoch: 965, Avg loss: 0.2970278490334749\n",
            "Epoch: 966, Avg loss: 0.2968908199109137\n",
            "Epoch: 967, Avg loss: 0.2977742612361908\n",
            "Epoch: 968, Avg loss: 0.296526546869427\n",
            "Epoch: 969, Avg loss: 0.2985193394124508\n",
            "Epoch: 970, Avg loss: 0.29712488455697894\n",
            "Epoch: 971, Avg loss: 0.2990862248465419\n",
            "Epoch: 972, Avg loss: 0.2979376997798681\n",
            "Epoch: 973, Avg loss: 0.29703225689008833\n",
            "Epoch: 974, Avg loss: 0.2979251387529075\n",
            "Epoch: 975, Avg loss: 0.29778290186077355\n",
            "Epoch: 976, Avg loss: 0.2980295821093023\n",
            "Epoch: 977, Avg loss: 0.29723274866119026\n",
            "Epoch: 978, Avg loss: 0.2968847225420177\n",
            "Epoch: 979, Avg loss: 0.29810660919174553\n",
            "Epoch: 980, Avg loss: 0.29790785619989035\n",
            "Epoch: 981, Avg loss: 0.29809744786471126\n",
            "Epoch: 982, Avg loss: 0.29816758846864105\n",
            "Epoch: 983, Avg loss: 0.2976955702528358\n",
            "Epoch: 984, Avg loss: 0.297255219751969\n",
            "Epoch: 985, Avg loss: 0.29843618981540204\n",
            "Epoch: 986, Avg loss: 0.2976838894188404\n",
            "Epoch: 987, Avg loss: 0.2971166682429612\n",
            "Epoch: 988, Avg loss: 0.297608869895339\n",
            "Epoch: 989, Avg loss: 0.29846512284129856\n",
            "Epoch: 990, Avg loss: 0.29648277508094906\n",
            "Epoch: 991, Avg loss: 0.2977287004701793\n",
            "Epoch: 992, Avg loss: 0.29741299971938134\n",
            "Epoch: 993, Avg loss: 0.29679417964071036\n",
            "Epoch: 994, Avg loss: 0.296165582165122\n",
            "Epoch: 995, Avg loss: 0.29659016989171505\n",
            "Epoch: 996, Avg loss: 0.2977179493755102\n",
            "Epoch: 997, Avg loss: 0.2974174527451396\n",
            "Epoch: 998, Avg loss: 0.2975544366054237\n",
            "Epoch: 999, Avg loss: 0.29734410233795644\n",
            "Epoch: 1000, Avg loss: 0.29669811818748715\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "  list_of_losses = list()\n",
        "  for x, y in ath_train_dataloder:\n",
        "    ath_clf.zero_grad()\n",
        "\n",
        "    predictions = ath_clf(x)\n",
        "\n",
        "    loss = criterion(predictions, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    list_of_losses.append(loss.item())\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}, Avg loss: {np.mean(list_of_losses)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Z-t6dTLrndMa"
      },
      "outputs": [],
      "source": [
        "list_of_labels = list()\n",
        "list_of_predictions = list()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for x, y in ath_test_dataloder:\n",
        "\n",
        "    _, predictions = torch.max(ath_clf(x), axis=1)\n",
        "\n",
        "    list_of_labels.extend(y.numpy())\n",
        "    list_of_predictions.extend(predictions.numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfFj3IxSnjzK",
        "outputId": "39daa02a-4e12-41d0-b5ba-13428d32e000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.771875\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_score(list_of_labels, list_of_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uEh7zu2sgaB"
      },
      "source": [
        "## KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jlAe4RF8zzml"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "train_dataset = pd.read_csv(\"/content/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RNd-tWf36REJ"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = \"cuda\"\n",
        "else:\n",
        "  device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "cuwWTTR28d7R"
      },
      "outputs": [],
      "source": [
        "class AuthorClassifier(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AuthorClassifier, self).__init__()\n",
        "\n",
        "    # linear layers (B, 380) -> (B, 5)\n",
        "    self.linear_layers = torch.nn.ModuleList()\n",
        "    self.linear_layers.append(torch.nn.Linear(380, 256))\n",
        "    self.linear_layers.append(torch.nn.Linear(256, 128))\n",
        "    self.linear_layers.append(torch.nn.Dropout(0.2)) # torch.nn.LeakyReLU(0.05)\n",
        "    self.linear_layers.append(torch.nn.Linear(128, 16))\n",
        "    self.linear_layers.append(torch.nn.Dropout(0.2))\n",
        "    self.linear_layers.append(torch.nn.Linear(16, 5))\n",
        "    self.linear_layers.append(torch.nn.Softmax())\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.linear_layers:\n",
        "      x = layer(x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "BFDR-K9OsiUo"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloader, optimizer, criterion):\n",
        "  model.train()\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    for x, y in dataloader:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      model.zero_grad()\n",
        "\n",
        "      predictions = model(x)\n",
        "\n",
        "      loss = criterion(predictions, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "  return model\n",
        "\n",
        "def test_model(model, dataloader):\n",
        "  list_of_labels = list()\n",
        "  list_of_predictions = list()\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x, y in dataloader:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      _, predictions = torch.max(model(x), axis=1)\n",
        "\n",
        "      list_of_labels.extend(y.detach().cpu().numpy())\n",
        "      list_of_predictions.extend(predictions.detach().cpu().numpy())\n",
        "\n",
        "  return accuracy_score(list_of_labels, list_of_predictions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7FXv8lIt-qH",
        "outputId": "6f44cd12-5e31-4212-b99f-70cd65cfe3a0"
      },
      "outputs": [],
      "source": [
        "kfold_dataset = KFold(n_splits=5, shuffle=True)\n",
        "list_of_accuracies = list()\n",
        "for train_index, test_index in kfold_dataset.split(train_dataset):\n",
        "\n",
        "\n",
        "  ath_clf = AuthorClassifier().to(device)\n",
        "\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(ath_clf.parameters(), lr=0.001)\n",
        "\n",
        "  ath_train_dataset = TextDataset(train_dataset.iloc[train_index])\n",
        "  ath_train_dataloder = torch.utils.data.DataLoader(dataset=ath_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "  ath_test_dataset = TextDataset(train_dataset.iloc[test_index])\n",
        "  ath_test_dataloder = torch.utils.data.DataLoader(dataset=ath_test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "  train_model(ath_clf, ath_train_dataloder, optimizer, criterion)\n",
        "  list_of_accuracies.append(test_model(ath_clf, ath_test_dataloder))\n",
        "  print(list_of_accuracies[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E00NyMec2QfM",
        "outputId": "253415c0-c6de-4c21-e697-f794169d5f91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg acc: 0.7919268388106417, std: 0.00846942027748635\n"
          ]
        }
      ],
      "source": [
        "print(f\"Avg acc: {np.mean(list_of_accuracies)}, std: {np.std(list_of_accuracies)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8j-qI0R5t1u",
        "outputId": "53fa6f94-9140-417f-ef41-69c8ad926298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg acc: 0.8000621087636933, std: 0.012064276373240326\n"
          ]
        }
      ],
      "source": [
        "print(f\"Avg acc: {np.mean(list_of_accuracies)}, std: {np.std(list_of_accuracies)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv67jO4DBPG9"
      },
      "source": [
        "## Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "QKkI-W67BSMc"
      },
      "outputs": [],
      "source": [
        "ath_dataset = TextDataset(\"/content/train.csv\")\n",
        "ath_dataloder = torch.utils.data.DataLoader(dataset=ath_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "ath_clf = AuthorClassifier().to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(ath_clf.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N29HAz6oBTJb",
        "outputId": "b814e2fb-5ae4-47ed-a3ee-53b4132a9b63"
      },
      "outputs": [],
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "  list_of_losses = list()\n",
        "  for x, y in ath_dataloder:\n",
        "    ath_clf.zero_grad()\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    predictions = ath_clf(x)\n",
        "\n",
        "    loss = criterion(predictions, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    list_of_losses.append(loss.item())\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}, Avg loss: {np.mean(list_of_losses)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "popykNa7_8bf"
      },
      "outputs": [],
      "source": [
        "test_dataframe = pd.read_csv(\"/content/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "0ZNTlkUcADkT",
        "outputId": "898f7c17-7984-4ca3-b0b9-1889a730d9bc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-379a849b-ab8a-43b3-95e8-76a3ba3275c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lung</th>\n",
              "      <th>council</th>\n",
              "      <th>solution</th>\n",
              "      <th>quite</th>\n",
              "      <th>rain</th>\n",
              "      <th>hair</th>\n",
              "      <th>skill</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>add</th>\n",
              "      <th>pull</th>\n",
              "      <th>...</th>\n",
              "      <th>stocking</th>\n",
              "      <th>near</th>\n",
              "      <th>oil</th>\n",
              "      <th>dive</th>\n",
              "      <th>many</th>\n",
              "      <th>run</th>\n",
              "      <th>tender</th>\n",
              "      <th>asleep</th>\n",
              "      <th>eat</th>\n",
              "      <th>sweep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 380 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-379a849b-ab8a-43b3-95e8-76a3ba3275c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-379a849b-ab8a-43b3-95e8-76a3ba3275c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-379a849b-ab8a-43b3-95e8-76a3ba3275c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6c6de557-67e9-428d-922f-25e0b20295bf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c6de557-67e9-428d-922f-25e0b20295bf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6c6de557-67e9-428d-922f-25e0b20295bf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   lung  council  solution  quite  rain  hair  skill  difficulty  add  pull  \\\n",
              "0     0        0         0      0     0     0      0           0    0     0   \n",
              "1     0        0         0      0     0     0      0           0    0     0   \n",
              "2     0        0         0      0     0     0      0           0    0     0   \n",
              "3     0        0         0      0     0     0      0           0    0     0   \n",
              "4     0        0         0      0     0     0      0           0    0     0   \n",
              "\n",
              "   ...  stocking  near  oil  dive  many  run  tender  asleep  eat  sweep  \n",
              "0  ...         0     0    0     0     0    0       0       0    0      0  \n",
              "1  ...         0     0    0     0     0    0       0       0    0      0  \n",
              "2  ...         0     0    0     0     0    0       0       0    0      0  \n",
              "3  ...         0     0    0     0     0    0       0       0    0      0  \n",
              "4  ...         0     0    0     0     0    0       0       0    0      0  \n",
              "\n",
              "[5 rows x 380 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "OLGkWVhPAFvS"
      },
      "outputs": [],
      "source": [
        "class TestTextDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, data):\n",
        "    super(TestTextDataset, self).__init__()\n",
        "\n",
        "    data = np.array(data)\n",
        "    self.X = data[:, 0:].astype(np.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample_X = self.X[index]\n",
        "\n",
        "    return sample_X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "GRs6Ao6OAca1"
      },
      "outputs": [],
      "source": [
        "test_dataset = TestTextDataset(test_dataframe)\n",
        "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfUzHgFIAeCO",
        "outputId": "45b3d357-8786-49e7-9c38-c3e42269e498"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "list_of_predictions = list()\n",
        "ath_clf.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for x in test_dataloader:\n",
        "    x = x.to(device)\n",
        "    _, predictions = torch.max(ath_clf(x), axis=1)\n",
        "\n",
        "    list_of_predictions.extend(predictions.detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zam8ug1JCWmE",
        "outputId": "8a200690-fe2a-4d74-e414-f77445d3b650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4, 1, 2, 2, 4, 4, 0, 2, 2, 0, 2, 2, 3, 0, 2, 3, 0, 3, 4, 0, 2, 4, 0, 1, 4, 2, 2, 4, 2, 3, 0, 3, 4, 4, 0, 1, 3, 2, 2, 4, 2, 2, 4, 3, 2, 1, 3, 0, 0, 4, 0, 2, 2, 4, 3, 3, 2, 0, 0, 0, 1, 2, 2, 3, 0, 1, 1, 2, 0, 4, 2, 4, 3, 4, 4, 2, 2, 2, 1, 0, 0, 3, 2, 2, 4, 2, 1, 2, 2, 1, 3, 4, 1, 4, 4, 3, 0, 1, 2, 2, 1, 0, 1, 2, 4, 2, 1, 1, 2, 3, 4, 0, 4, 1, 3, 0, 0, 3, 2, 2, 4, 4, 4, 3, 2, 4, 2, 1, 1, 0, 4, 0, 2, 2, 4, 3, 1, 3, 2, 1, 1, 1, 0, 2, 0, 0, 3, 3, 0, 4, 0, 1, 0, 3, 4, 4, 4, 0, 3, 3, 2, 1, 4, 0, 3, 3, 4, 0, 0, 0, 4, 3, 2, 2, 4, 0, 0, 2, 4, 3, 2, 0, 0, 3, 1, 2, 1, 1, 2, 4, 4, 3, 3, 4, 3, 2, 4, 1, 2, 3, 3, 1, 1, 1, 3, 4, 0, 4, 3, 2, 1, 0, 1, 2, 2, 4, 2, 0, 4, 2, 1, 3, 3, 3, 1, 1, 4, 0, 2, 4, 1, 3, 3, 4, 1, 3, 2, 3, 0, 4, 0, 0, 2, 1, 4, 4, 2, 0, 3, 2, 1, 3, 4, 1, 4, 1, 3, 3, 0, 2, 0, 0, 4, 2, 1, 4, 1, 3, 1, 3, 1, 4, 3, 1, 3, 1, 2, 3, 2, 3, 3, 4, 3, 1, 0, 2, 3, 0, 4, 4, 0, 0, 2, 3, 2, 0, 4, 3, 3, 3, 0, 2, 1, 3, 2, 4, 1, 1, 2, 1, 3, 0, 2, 1, 1, 2, 3, 2, 1, 4, 2, 3, 0, 0, 4, 4, 2, 3, 1, 0, 4, 0, 1, 1, 4, 0, 2, 1, 4, 2, 2, 2, 2, 1, 1, 1, 3, 4, 4, 4, 0, 0, 1, 2, 4, 4, 1, 0, 0, 1, 3, 1, 0, 4, 2, 3, 4, 2, 3, 3, 1, 0, 0, 2, 3, 1, 1, 0, 0, 3, 2, 0, 2, 2, 4, 4, 2, 4, 1, 4, 1, 1, 0, 0, 1, 3, 0, 4, 4, 0, 1, 4, 4, 1, 0, 4, 3, 0, 1, 4, 2, 0, 3, 4, 3, 0, 0, 2, 4, 1, 3, 2, 1, 3, 1, 1, 1, 2, 1, 0, 2, 2, 4, 1, 3, 2, 1, 0, 1, 4, 4, 3, 3, 0, 4, 2, 3, 2, 0, 4, 4, 4, 2, 1, 4, 1, 3, 2, 0, 3, 4, 1, 1, 1, 4, 1, 0, 2, 2, 3, 1, 2, 0, 0, 3, 0, 3, 0, 1, 4, 3, 3, 1, 2, 4, 2, 1, 2, 2, 0, 4, 3, 0, 4, 2, 4, 4, 2, 2, 1, 1, 2, 1, 0, 2, 1, 0, 3, 2, 4, 0, 4, 4, 3, 0, 4, 0, 1, 4, 4, 0, 2, 0, 4, 3, 3, 4, 0, 3, 4, 4, 2, 2, 2, 2, 1, 2, 0, 3, 4, 1, 1, 3, 3, 4, 2, 0, 2, 2, 2, 1, 3, 1, 3, 2, 2, 4, 0, 3, 0, 4, 0, 0, 4, 3, 0, 2, 1, 1, 0, 1, 2, 2, 3, 2, 1, 2, 4, 3, 0, 4, 3, 4, 1, 3, 4, 3, 2, 0, 4, 1, 4, 0, 4, 4, 3, 3, 1, 3, 3, 2, 4, 0, 0, 3, 3, 3, 4, 2, 1, 0, 0, 2, 2, 1, 3, 0, 4, 2, 4, 4, 1, 0, 3, 2, 2, 3, 0, 2, 0, 4, 4, 2, 2, 1, 1, 0, 2, 1, 4, 0, 4, 2, 3, 1, 3, 4, 1, 2, 2, 4, 3, 2, 3, 1, 2, 3, 1, 1, 0, 3, 0, 1, 2, 2, 0, 3, 2, 3, 4, 4, 4, 3, 4, 1, 3, 1, 3, 0, 4, 4, 3, 0, 2, 3, 0, 1, 4, 2, 2, 1, 4, 4, 3, 4, 0, 4, 0, 1, 4, 0, 0, 3, 2, 3, 3, 1, 4, 2, 2, 1, 3, 2, 4, 2, 1, 2, 0, 0, 1, 0, 1, 1, 4, 4, 2, 2, 2, 3, 3, 2, 4, 0, 4, 1, 2, 4, 3, 1, 0, 3, 4, 4, 1, 1, 1, 3, 2, 2, 1, 4, 2, 2, 0, 4, 4, 4, 3, 2, 1, 0, 2, 2, 4, 0, 0, 0, 1, 2, 0, 3, 4, 2, 3, 0, 1, 0, 2, 0, 3, 4, 0, 3, 3, 0, 4, 2, 4, 4, 2, 0, 3, 1, 2, 4, 2, 4, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(list_of_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR8vuqD-CYTh",
        "outputId": "01807d33-980f-42c0-bf0d-d218abfd4c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Olivia Bennett' 'Ethan Brooks' 'Liam Carter' 'Liam Carter'\n",
            " 'Olivia Bennett' 'Olivia Bennett' 'Ava Thompson' 'Liam Carter'\n",
            " 'Liam Carter' 'Ava Thompson' 'Liam Carter' 'Liam Carter' 'Mason Reed'\n",
            " 'Ava Thompson' 'Liam Carter' 'Mason Reed' 'Ava Thompson' 'Mason Reed'\n",
            " 'Olivia Bennett' 'Ava Thompson' 'Liam Carter' 'Olivia Bennett'\n",
            " 'Ava Thompson' 'Ethan Brooks' 'Olivia Bennett' 'Liam Carter'\n",
            " 'Liam Carter' 'Olivia Bennett' 'Liam Carter' 'Mason Reed' 'Ava Thompson'\n",
            " 'Mason Reed' 'Olivia Bennett' 'Olivia Bennett' 'Ava Thompson'\n",
            " 'Ethan Brooks' 'Mason Reed' 'Liam Carter' 'Liam Carter' 'Olivia Bennett'\n",
            " 'Liam Carter' 'Liam Carter' 'Olivia Bennett' 'Mason Reed' 'Liam Carter'\n",
            " 'Ethan Brooks' 'Mason Reed' 'Ava Thompson' 'Ava Thompson'\n",
            " 'Olivia Bennett' 'Ava Thompson' 'Liam Carter' 'Liam Carter'\n",
            " 'Olivia Bennett' 'Mason Reed' 'Mason Reed' 'Liam Carter' 'Ava Thompson'\n",
            " 'Ava Thompson' 'Ava Thompson' 'Ethan Brooks' 'Liam Carter' 'Liam Carter'\n",
            " 'Mason Reed' 'Ava Thompson' 'Ethan Brooks' 'Ethan Brooks' 'Liam Carter'\n",
            " 'Ava Thompson' 'Olivia Bennett' 'Liam Carter' 'Olivia Bennett'\n",
            " 'Mason Reed' 'Olivia Bennett' 'Olivia Bennett' 'Liam Carter'\n",
            " 'Liam Carter' 'Liam Carter' 'Ethan Brooks' 'Ava Thompson' 'Ava Thompson'\n",
            " 'Mason Reed' 'Liam Carter' 'Liam Carter' 'Olivia Bennett' 'Liam Carter'\n",
            " 'Ethan Brooks' 'Liam Carter' 'Liam Carter' 'Ethan Brooks' 'Mason Reed'\n",
            " 'Olivia Bennett' 'Ethan Brooks' 'Olivia Bennett' 'Olivia Bennett'\n",
            " 'Mason Reed' 'Ava Thompson' 'Ethan Brooks' 'Liam Carter' 'Liam Carter'\n",
            " 'Ethan Brooks' 'Ava Thompson' 'Ethan Brooks' 'Liam Carter'\n",
            " 'Olivia Bennett' 'Liam Carter' 'Ethan Brooks' 'Ethan Brooks'\n",
            " 'Liam Carter' 'Mason Reed' 'Olivia Bennett' 'Ava Thompson'\n",
            " 'Olivia Bennett' 'Ethan Brooks' 'Mason Reed' 'Ava Thompson'\n",
            " 'Ava Thompson' 'Mason Reed' 'Liam Carter' 'Liam Carter' 'Olivia Bennett'\n",
            " 'Olivia Bennett' 'Olivia Bennett' 'Mason Reed' 'Liam Carter'\n",
            " 'Olivia Bennett' 'Liam Carter' 'Ethan Brooks' 'Ethan Brooks'\n",
            " 'Ava Thompson' 'Olivia Bennett' 'Ava Thompson' 'Liam Carter'\n",
            " 'Liam Carter' 'Olivia Bennett' 'Mason Reed' 'Ethan Brooks' 'Mason Reed'\n",
            " 'Liam Carter' 'Ethan Brooks' 'Ethan Brooks' 'Ethan Brooks' 'Ava Thompson'\n",
            " 'Liam Carter' 'Ava Thompson' 'Ava Thompson' 'Mason Reed' 'Mason Reed'\n",
            " 'Ava Thompson' 'Olivia Bennett' 'Ava Thompson' 'Ethan Brooks'\n",
            " 'Ava Thompson' 'Mason Reed' 'Olivia Bennett' 'Olivia Bennett'\n",
            " 'Olivia Bennett' 'Ava Thompson' 'Mason Reed' 'Mason Reed' 'Liam Carter'\n",
            " 'Ethan Brooks' 'Olivia Bennett' 'Ava Thompson' 'Mason Reed' 'Mason Reed'\n",
            " 'Olivia Bennett' 'Ava Thompson' 'Ava Thompson' 'Ava Thompson'\n",
            " 'Olivia Bennett' 'Mason Reed' 'Liam Carter' 'Liam Carter'\n",
            " 'Olivia Bennett' 'Ava Thompson' 'Ava Thompson' 'Liam Carter'\n",
            " 'Olivia Bennett' 'Mason Reed' 'Liam Carter' 'Ava Thompson' 'Ava Thompson'\n",
            " 'Mason Reed' 'Ethan Brooks' 'Liam Carter' 'Ethan Brooks' 'Ethan Brooks'\n",
            " 'Liam Carter' 'Olivia Bennett' 'Olivia Bennett' 'Mason Reed' 'Mason Reed'\n",
            " 'Olivia Bennett' 'Mason Reed' 'Liam Carter' 'Olivia Bennett'\n",
            " 'Ethan Brooks' 'Liam Carter' 'Mason Reed' 'Mason Reed' 'Ethan Brooks'\n",
            " 'Ethan Brooks' 'Ethan Brooks' 'Mason Reed' 'Olivia Bennett'\n",
            " 'Ava Thompson' 'Olivia Bennett' 'Mason Reed' 'Liam Carter' 'Ethan Brooks'\n",
            " 'Ava Thompson' 'Ethan Brooks' 'Liam Carter' 'Liam Carter'\n",
            " 'Olivia Bennett' 'Liam Carter' 'Ava Thompson' 'Olivia Bennett'\n",
            " 'Liam Carter' 'Ethan Brooks' 'Mason Reed' 'Mason Reed' 'Mason Reed'\n",
            " 'Ethan Brooks' 'Ethan Brooks' 'Olivia Bennett' 'Ava Thompson'\n",
            " 'Liam Carter' 'Olivia Bennett' 'Ethan Brooks' 'Mason Reed' 'Mason Reed'\n",
            " 'Olivia Bennett' 'Ethan Brooks' 'Mason Reed' 'Liam Carter' 'Mason Reed'\n",
            " 'Ava Thompson' 'Olivia Bennett' 'Ava Thompson' 'Ava Thompson'\n",
            " 'Liam Carter' 'Ethan Brooks' 'Olivia Bennett' 'Olivia Bennett'\n",
            " 'Liam Carter' 'Ava Thompson' 'Mason Reed' 'Liam Carter' 'Ethan Brooks'\n",
            " 'Mason Reed' 'Olivia Bennett' 'Ethan Brooks' 'Olivia Bennett'\n",
            " 'Ethan Brooks' 'Mason Reed' 'Mason Reed' 'Ava Thompson' 'Liam Carter'\n",
            " 'Ava Thompson' 'Ava Thompson' 'Olivia Bennett' 'Liam Carter'\n",
            " 'Ethan Brooks' 'Olivia Bennett' 'Ethan Brooks' 'Mason Reed'\n",
            " 'Ethan Brooks' 'Mason Reed' 'Ethan Brooks' 'Olivia Bennett' 'Mason Reed'\n",
            " 'Ethan Brooks' 'Mason Reed' 'Ethan Brooks' 'Liam Carter' 'Mason Reed'\n",
            " 'Liam Carter' 'Mason Reed' 'Mason Reed' 'Olivia Bennett' 'Mason Reed'\n",
            " 'Ethan Brooks' 'Ava Thompson' 'Liam Carter' 'Mason Reed' 'Ava Thompson'\n",
            " 'Olivia Bennett' 'Olivia Bennett' 'Ava Thompson' 'Ava Thompson'\n",
            " 'Liam Carter' 'Mason Reed' 'Liam Carter' 'Ava Thompson' 'Olivia Bennett'\n",
            " 'Mason Reed' 'Mason Reed' 'Mason Reed' 'Ava Thompson' 'Liam Carter'\n",
            " 'Ethan Brooks' 'Mason Reed' 'Liam Carter' 'Olivia Bennett' 'Ethan Brooks'\n",
            " 'Ethan Brooks' 'Liam Carter' 'Ethan Brooks' 'Mason Reed' 'Ava Thompson'\n",
            " 'Liam Carter' 'Ethan Brooks' 'Ethan Brooks' 'Liam Carter' 'Mason Reed'\n",
            " 'Liam Carter' 'Ethan Brooks' 'Olivia Bennett' 'Liam Carter' 'Mason Reed'\n",
            " 'Ava Thompson' 'Ava Thompson' 'Olivia Bennett' 'Olivia Bennett'\n",
            " 'Liam Carter' 'Mason Reed' 'Ethan Brooks' 'Ava Thompson' 'Olivia Bennett'\n",
            " 'Ava Thompson' 'Ethan Brooks' 'Ethan Brooks' 'Olivia Bennett'\n",
            " 'Ava Thompson' 'Liam Carter' 'Ethan Brooks' 'Olivia Bennett'\n",
            " 'Liam Carter' 'Liam Carter' 'Liam Carter' 'Liam Carter' 'Ethan Brooks'\n",
            " 'Ethan Brooks' 'Ethan Brooks' 'Mason Reed' 'Olivia Bennett'\n",
            " 'Olivia Bennett' 'Olivia Bennett' 'Ava Thompson' 'Ava Thompson'\n",
            " 'Ethan Brooks' 'Liam Carter' 'Olivia Bennett' 'Olivia Bennett'\n",
            " 'Ethan Brooks' 'Ava Thompson' 'Ava Thompson' 'Ethan Brooks' 'Mason Reed'\n",
            " 'Ethan Brooks' 'Ava Thompson' 'Olivia Bennett' 'Liam Carter' 'Mason Reed'\n",
            " 'Olivia Bennett' 'Liam Carter' 'Mason Reed' 'Mason Reed' 'Ethan Brooks'\n",
            " 'Ava Thompson' 'Ava Thompson' 'Liam Carter' 'Mason Reed' 'Ethan Brooks'\n",
            " 'Ethan Brooks' 'Ava Thompson' 'Ava Thompson' 'Mason Reed' 'Liam Carter'\n",
            " 'Ava Thompson' 'Liam Carter' 'Liam Carter' 'Olivia Bennett'\n",
            " 'Olivia Bennett' 'Liam Carter' 'Olivia Bennett' 'Ethan Brooks'\n",
            " 'Olivia Bennett' 'Ethan Brooks' 'Ethan Brooks' 'Ava Thompson'\n",
            " 'Ava Thompson' 'Ethan Brooks' 'Mason Reed' 'Ava Thompson'\n",
            " 'Olivia Bennett' 'Olivia Bennett' 'Ava Thompson' 'Ethan Brooks'\n",
            " 'Olivia Bennett' 'Olivia Bennett' 'Ethan Brooks' 'Ava Thompson'\n",
            " 'Olivia Bennett' 'Mason Reed' 'Ava Thompson' 'Ethan Brooks'\n",
            " 'Olivia Bennett' 'Liam Carter' 'Ava Thompson' 'Mason Reed'\n",
            " 'Olivia Bennett' 'Mason Reed' 'Ava Thompson' 'Ava Thompson' 'Liam Carter'\n",
            " 'Olivia Bennett' 'Ethan Brooks' 'Mason Reed' 'Liam Carter' 'Ethan Brooks'\n",
            " 'Mason Reed' 'Ethan Brooks' 'Ethan Brooks' 'Ethan Brooks' 'Liam Carter'\n",
            " 'Ethan Brooks' 'Ava Thompson' 'Liam Carter' 'Liam Carter'\n",
            " 'Olivia Bennett' 'Ethan Brooks' 'Mason Reed' 'Liam Carter' 'Ethan Brooks'\n",
            " 'Ava Thompson' 'Ethan Brooks' 'Olivia Bennett' 'Olivia Bennett'\n",
            " 'Mason Reed' 'Mason Reed' 'Ava Thompson' 'Olivia Bennett' 'Liam Carter'\n",
            " 'Mason Reed' 'Liam Carter' 'Ava Thompson' 'Olivia Bennett'\n",
            " 'Olivia Bennett' 'Olivia Bennett' 'Liam Carter' 'Ethan Brooks'\n",
            " 'Olivia Bennett' 'Ethan Brooks' 'Mason Reed' 'Liam Carter' 'Ava Thompson'\n",
            " 'Mason Reed' 'Olivia Bennett' 'Ethan Brooks' 'Ethan Brooks'\n",
            " 'Ethan Brooks' 'Olivia Bennett' 'Ethan Brooks' 'Ava Thompson'\n",
            " 'Liam Carter' 'Liam Carter' 'Mason Reed' 'Ethan Brooks' 'Liam Carter'\n",
            " 'Ava Thompson' 'Ava Thompson' 'Mason Reed' 'Ava Thompson' 'Mason Reed'\n",
            " 'Ava Thompson' 'Ethan Brooks' 'Olivia Bennett' 'Mason Reed' 'Mason Reed'\n",
            " 'Ethan Brooks' 'Liam Carter' 'Olivia Bennett' 'Liam Carter'\n",
            " 'Ethan Brooks' 'Liam Carter' 'Liam Carter' 'Ava Thompson'\n",
            " 'Olivia Bennett' 'Mason Reed' 'Ava Thompson' 'Olivia Bennett'\n",
            " 'Liam Carter' 'Olivia Bennett' 'Olivia Bennett' 'Liam Carter'\n",
            " 'Liam Carter' 'Ethan Brooks' 'Ethan Brooks' 'Liam Carter' 'Ethan Brooks'\n",
            " 'Ava Thompson' 'Liam Carter' 'Ethan Brooks' 'Ava Thompson' 'Mason Reed'\n",
            " 'Liam Carter' 'Olivia Bennett' 'Ava Thompson' 'Olivia Bennett'\n",
            " 'Olivia Bennett' 'Mason Reed' 'Ava Thompson' 'Olivia Bennett'\n",
            " 'Ava Thompson' 'Ethan Brooks' 'Olivia Bennett' 'Olivia Bennett'\n",
            " 'Ava Thompson' 'Liam Carter' 'Ava Thompson' 'Olivia Bennett' 'Mason Reed'\n",
            " 'Mason Reed' 'Olivia Bennett' 'Ava Thompson' 'Mason Reed'\n",
            " 'Olivia Bennett' 'Olivia Bennett' 'Liam Carter' 'Liam Carter'\n",
            " 'Liam Carter' 'Liam Carter' 'Ethan Brooks' 'Liam Carter' 'Ava Thompson'\n",
            " 'Mason Reed' 'Olivia Bennett' 'Ethan Brooks' 'Ethan Brooks' 'Mason Reed'\n",
            " 'Mason Reed' 'Olivia Bennett' 'Liam Carter' 'Ava Thompson' 'Liam Carter'\n",
            " 'Liam Carter' 'Liam Carter' 'Ethan Brooks' 'Mason Reed' 'Ethan Brooks'\n",
            " 'Mason Reed' 'Liam Carter' 'Liam Carter' 'Olivia Bennett' 'Ava Thompson'\n",
            " 'Mason Reed' 'Ava Thompson' 'Olivia Bennett' 'Ava Thompson'\n",
            " 'Ava Thompson' 'Olivia Bennett' 'Mason Reed' 'Ava Thompson' 'Liam Carter'\n",
            " 'Ethan Brooks' 'Ethan Brooks' 'Ava Thompson' 'Ethan Brooks' 'Liam Carter'\n",
            " 'Liam Carter' 'Mason Reed' 'Liam Carter' 'Ethan Brooks' 'Liam Carter'\n",
            " 'Olivia Bennett' 'Mason Reed' 'Ava Thompson' 'Olivia Bennett'\n",
            " 'Mason Reed' 'Olivia Bennett' 'Ethan Brooks' 'Mason Reed'\n",
            " 'Olivia Bennett' 'Mason Reed' 'Liam Carter' 'Ava Thompson'\n",
            " 'Olivia Bennett' 'Ethan Brooks' 'Olivia Bennett' 'Ava Thompson'\n",
            " 'Olivia Bennett' 'Olivia Bennett' 'Mason Reed' 'Mason Reed'\n",
            " 'Ethan Brooks' 'Mason Reed' 'Mason Reed' 'Liam Carter' 'Olivia Bennett'\n",
            " 'Ava Thompson' 'Ava Thompson' 'Mason Reed' 'Mason Reed' 'Mason Reed'\n",
            " 'Olivia Bennett' 'Liam Carter' 'Ethan Brooks' 'Ava Thompson'\n",
            " 'Ava Thompson' 'Liam Carter' 'Liam Carter' 'Ethan Brooks' 'Mason Reed'\n",
            " 'Ava Thompson' 'Olivia Bennett' 'Liam Carter' 'Olivia Bennett'\n",
            " 'Olivia Bennett' 'Ethan Brooks' 'Ava Thompson' 'Mason Reed' 'Liam Carter'\n",
            " 'Liam Carter' 'Mason Reed' 'Ava Thompson' 'Liam Carter' 'Ava Thompson'\n",
            " 'Olivia Bennett' 'Olivia Bennett' 'Liam Carter' 'Liam Carter'\n",
            " 'Ethan Brooks' 'Ethan Brooks' 'Ava Thompson' 'Liam Carter' 'Ethan Brooks'\n",
            " 'Olivia Bennett' 'Ava Thompson' 'Olivia Bennett' 'Liam Carter'\n",
            " 'Mason Reed' 'Ethan Brooks' 'Mason Reed' 'Olivia Bennett' 'Ethan Brooks'\n",
            " 'Liam Carter' 'Liam Carter' 'Olivia Bennett' 'Mason Reed' 'Liam Carter'\n",
            " 'Mason Reed' 'Ethan Brooks' 'Liam Carter' 'Mason Reed' 'Ethan Brooks'\n",
            " 'Ethan Brooks' 'Ava Thompson' 'Mason Reed' 'Ava Thompson' 'Ethan Brooks'\n",
            " 'Liam Carter' 'Liam Carter' 'Ava Thompson' 'Mason Reed' 'Liam Carter'\n",
            " 'Mason Reed' 'Olivia Bennett' 'Olivia Bennett' 'Olivia Bennett'\n",
            " 'Mason Reed' 'Olivia Bennett' 'Ethan Brooks' 'Mason Reed' 'Ethan Brooks'\n",
            " 'Mason Reed' 'Ava Thompson' 'Olivia Bennett' 'Olivia Bennett'\n",
            " 'Mason Reed' 'Ava Thompson' 'Liam Carter' 'Mason Reed' 'Ava Thompson'\n",
            " 'Ethan Brooks' 'Olivia Bennett' 'Liam Carter' 'Liam Carter'\n",
            " 'Ethan Brooks' 'Olivia Bennett' 'Olivia Bennett' 'Mason Reed'\n",
            " 'Olivia Bennett' 'Ava Thompson' 'Olivia Bennett' 'Ava Thompson'\n",
            " 'Ethan Brooks' 'Olivia Bennett' 'Ava Thompson' 'Ava Thompson'\n",
            " 'Mason Reed' 'Liam Carter' 'Mason Reed' 'Mason Reed' 'Ethan Brooks'\n",
            " 'Olivia Bennett' 'Liam Carter' 'Liam Carter' 'Ethan Brooks' 'Mason Reed'\n",
            " 'Liam Carter' 'Olivia Bennett' 'Liam Carter' 'Ethan Brooks' 'Liam Carter'\n",
            " 'Ava Thompson' 'Ava Thompson' 'Ethan Brooks' 'Ava Thompson'\n",
            " 'Ethan Brooks' 'Ethan Brooks' 'Olivia Bennett' 'Olivia Bennett'\n",
            " 'Liam Carter' 'Liam Carter' 'Liam Carter' 'Mason Reed' 'Mason Reed'\n",
            " 'Liam Carter' 'Olivia Bennett' 'Ava Thompson' 'Olivia Bennett'\n",
            " 'Ethan Brooks' 'Liam Carter' 'Olivia Bennett' 'Mason Reed' 'Ethan Brooks'\n",
            " 'Ava Thompson' 'Mason Reed' 'Olivia Bennett' 'Olivia Bennett'\n",
            " 'Ethan Brooks' 'Ethan Brooks' 'Ethan Brooks' 'Mason Reed' 'Liam Carter'\n",
            " 'Liam Carter' 'Ethan Brooks' 'Olivia Bennett' 'Liam Carter' 'Liam Carter'\n",
            " 'Ava Thompson' 'Olivia Bennett' 'Olivia Bennett' 'Olivia Bennett'\n",
            " 'Mason Reed' 'Liam Carter' 'Ethan Brooks' 'Ava Thompson' 'Liam Carter'\n",
            " 'Liam Carter' 'Olivia Bennett' 'Ava Thompson' 'Ava Thompson'\n",
            " 'Ava Thompson' 'Ethan Brooks' 'Liam Carter' 'Ava Thompson' 'Mason Reed'\n",
            " 'Olivia Bennett' 'Liam Carter' 'Mason Reed' 'Ava Thompson' 'Ethan Brooks'\n",
            " 'Ava Thompson' 'Liam Carter' 'Ava Thompson' 'Mason Reed' 'Olivia Bennett'\n",
            " 'Ava Thompson' 'Mason Reed' 'Mason Reed' 'Ava Thompson' 'Olivia Bennett'\n",
            " 'Liam Carter' 'Olivia Bennett' 'Olivia Bennett' 'Liam Carter'\n",
            " 'Ava Thompson' 'Mason Reed' 'Ethan Brooks' 'Liam Carter' 'Olivia Bennett'\n",
            " 'Liam Carter' 'Olivia Bennett' 'Ava Thompson' 'Ava Thompson']\n"
          ]
        }
      ],
      "source": [
        "print(ath_dataset.le.inverse_transform(list_of_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlkLOq2_DdEk"
      },
      "source": [
        "### Dynamic Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "bqezm1ynDfh7"
      },
      "outputs": [],
      "source": [
        "class AuthorClassifier(torch.nn.Module):\n",
        "  def __init__(self, input_features, neurons_in_layers):\n",
        "    super(AuthorClassifier, self).__init__()\n",
        "\n",
        "    # linear layers (B, 380) -> (B, 5)\n",
        "    self.linear_layers = torch.nn.ModuleList()\n",
        "\n",
        "    for layer_index, neuron in enumerate(neurons_in_layers):\n",
        "      self.linear_layers.append(torch.nn.Linear(input_features, neuron))\n",
        "      if layer_index >= 2:\n",
        "        self.linear_layers.append(torch.nn.LeakyReLU(0.05))\n",
        "      input_features = neuron\n",
        "\n",
        "    self.linear_layers.append(torch.nn.Softmax())\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.linear_layers:\n",
        "      x = layer(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GddFNxCSD-1L",
        "outputId": "f6b8dd97-a4e9-4da5-c39b-19c2f699a57d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 50])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "clf = AuthorClassifier(input_features=400, neurons_in_layers=[5, 10, 20, 100, 50])\n",
        "\n",
        "random_input = torch.randn((10, 400))\n",
        "print(clf(random_input).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz-JQZO-EO9o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.12.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "d98115f835a97365e29325b61fff4dda3750a4cf20fbdffc5d0b821e6e971d31"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
